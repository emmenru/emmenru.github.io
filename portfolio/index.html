<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Emma Frid &mdash; Portfolio</title>
<!--

Template 2086 Multi Color

http://www.tooplate.com/view/2086-multi-color

-->
    <!-- load stylesheets -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,400">  
    <!-- Google web font "Open Sans" -->
    <link rel="stylesheet" href="font-awesome-4.5.0/css/font-awesome.min.css">                
    <!-- Font Awesome -->
    <link rel="stylesheet" href="css/bootstrap.min.css">                                      
    <!-- Bootstrap style -->
    <link rel="stylesheet" href="css/hero-slider-style.css">                              
    <!-- Hero slider style (https://codyhouse.co/gem/hero-slider/) -->
    <link rel="stylesheet" href="css/magnific-popup.css">                                 
    <!-- Magnific popup style (http://dimsemenov.com/plugins/magnific-popup/) -->
    <link rel="stylesheet" href="css/tooplate-style.css">                                   

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
          <![endif]-->
</head>

    <body>
        
        <!-- Content -->
        <div class="cd-hero">

            <!-- Navigation -->        
            <div class="cd-slider-nav">
                <nav class="navbar">
                    <div class="tm-navbar-bg">
                        
                        <a class="navbar-brand text-uppercase fw-bold" href="#"><i class="fa fa-briefcase tm-brand-icon"></i>Emma FRID </a>

                        <button class="navbar-toggler hidden-lg-up" type="button" data-toggle="collapse" data-target="#tmNavbar">
                            &#9776;
                        </button>
                        <div class="collapse navbar-toggleable-md text-xs-center text-uppercase tm-navbar" id="tmNavbar">
                            <ul class="nav navbar-nav">
                                <li class="nav-item active selected">
                                    <a class="nav-link" href="#0" data-no="1">#1 <span class="sr-only">(current)</span></a>
                                </li>                                
                                <li class="nav-item">
                                    <a class="nav-link" href="#0" data-no="2">#2</a>
                                </li>
                                <li class="nav-item">
                                    <a class="nav-link" href="#0" data-no="3">#3</a>
                                </li>
                                <li class="nav-item">
                                    <a class="nav-link" href="#0" data-no="4">#4</a>
                                </li>
                                <li class="nav-item">
                                    <a class="nav-link" href="#0" data-no="5">#5</a>
                                </li>
                            </ul>
                        </div>                        
                    </div>

                </nav>
            </div> 

            <ul class="cd-hero-slider">

                <!-- Page 1 Gallery One -->
                <li class="selected">                    
                    <div class="cd-full-width">
                        <div class="container-fluid js-tm-page-content" data-page-no="1" data-page-type="gallery">                        
                            <div class="tm-img-gallery-container">

                                <!-- Gallery Two pop up connected with JS code below -->
                                    
                                    <!--<br>-->
                                    <div class="tm-img-gallery-info-container">     
                                        <br>
                                        <h2 class="tm-text-title tm-gallery-title"><span class="tm-white">Perception of Robot Sounds</span></h2>
                                        <p class="tm-text"><a href="https://link.springer.com/article/10.1007/s12369-021-00788-4">Link to paper</a>
                                        </p>                                     
                                    </div>

                                    <div class="tm-img-gallery gallery-one">
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj1/fig1-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>One</span></h2>-->
                                                <p class="tm-figure-description">The NAO robot</p>
                                                <a href="img/projects/proj1/fig1.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj1/fig2-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Two</span></h2>-->
                                                <p class="tm-figure-description">Project workflow</p>
                                                <a href="img/projects/proj1/fig2.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj1/fig10-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Four</span></h2>-->
                                                <p class="tm-figure-description">Interaction graph for joyful stimuli</p>
                                                <a href="img/projects/proj1/fig10.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj1/fig9-tn.jpg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Three</span></h2>-->
                                                <p class="tm-figure-description">Mean ratings for joyful stimuli</p>
                                                <a href="img/projects/proj1/fig9.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                </div> <!-- .tm-img-gallery-container -->

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Background</h2>
                                                    <p class="tm-text">
                                                        It is well known that the sounds procuded by robots can have a significant effect on how the robot is perceived by a human. This project focused on exploring if sounds inherent to robot movements (for example engine and motor sounds, glitches, etc.) can be processed in a way that enhances, rather than disturbs, emotion conveyed through robot gestures. To improve robot communication, synthesized sounds were added to the mechanical sounds produced by a robot. 
                                                        <!-- We refer to this augmentation and processing of existing robot sounds as <i>blended sonification</i>. <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Sonification">Sonification</a> is the use of non-speech audio to convey information or perceptualize data. -->
                                                        
                                                    </p>
                                            </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Aim</h2>
                                                    <p class="tm-text">The goal of this project was to design and evaluate non-speech sounds that can enhance and support the emotional expression of robot gestures. More specifically, the aim was to explore if mechanical sounds inherent to robot movements can be blended with carefully designed musical sounds to more efficiently communicate the emotions <i>frustration</i>, <i>sadness</i>, <i>joy</i>, and <i>relaxation</i>.</p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>  
                                                  
                            <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Approach</h2>
                                            <p class="tm-text">
                                            I led this project from start to finish, designing the experiment, collecting and cleaning the data, and conducting in-depth analysis to extract meaningful insights. The study consisted of two parts, <b>Experiment 1</b>, which focused on descriptions of sounds produced by expressive movements of a <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Nao_(robot)">NAO robot</a>, and <b>Experiment 2</b>, which focused on perceptual ratings of a) unprocessed mechanical robot sounds, versus b) processed (i.e. musically augmented) robot sounds. 
                                            <br><br>
                                            In <b>Experiment 1</b>, n=31 participants listened to the sounds and described them using free-form text annotations. Analysis of this data focused on aspects related to motion and emotion. In <b>Experiment 2</b>, the participants rated emotions conveyed by the sounds on a set of emotional scales. This data was analyzed using Two-Way Repeated Measures ANOVAs.
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Insights and impact</h2>
                                            <p class="tm-text">
                                            <b>Experiment 1</b> revealed a disconnect between the robot's emotional expression and the sounds inherently produced by its movements. Interestingly, the mechanical sounds that that the robot produced when performing a joyful gesture were perceived as <i>frustrated</i>. This kind of mismatch could potentially lead to miscommunication between robots and humans. 
                                            <br>
                                            <br>   
                                            In <b>Experiment 2</b>, musical sounds were added to the mechanical robot sounds to counteract potential miscommunication. This technique proved to successfully enhance the emotional message conveyed by sound models designed to communicate <i>frustration</i> and <i>joy</i>. 
                                            <br>
                                            <br>
                                            These findings offer valuable insights for robot sound design. The work was published in the International Journal of <a href="https://link.springer.com/journal/12369">Social Robotics</a> (Springer, five year impact factor 4.8, ranking among the 20 top Social Robotics journals). The paper has been cited 31 times.
                                            </p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                                    <div class="row">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Tools</h2>
                                                    <p class="tm-text">
                                                       R, SPSS, Max/MSP. 
                                                    </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Methods</h2>
                                                    <p class="tm-text">Analysis of variance (ANOVA) for statistical testing, text analysis techniques for data extraction, sound synthesis, subjective evaluation through user ratings.</p>     
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Links</h2>
                                                    <p class="tm-text">
                                                        <a class="link-opacity-10" href="https://link.springer.com/article/10.1007/s12369-021-00788-4">Publication</a>,
                                                        <a class="link-opacity-10" href="https://link.springer.com/article/10.1007/s12369-021-00788-4#availability-of-data-and-materials">files and data</a>, 
                                                        <a class="link-opacity-10" href="https://www.kth.se/hct/mid/research/smc/projects/sonao-1.895500">SONAO project page</a>. 

                                                    </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>   
                                </div>                                 
                            
                        </div>                                        
                    </div>                    
                </li>

                <!-- Page 2  -->
                <li>
                    <div class="cd-full-width">
                        <div class="container-fluid js-tm-page-content" data-page-no="2" data-page-type="gallery">                        
                            <div class="tm-img-gallery-container">
                                
                                <!-- Gallery Two pop up connected with JS code below -->                                    
                                    <div class="tm-img-gallery-info-container">    
                                        <br>                             
                                        <h2 class="tm-text-title tm-gallery-title"><span class="tm-white">The Computer Music Gender Gap</span></h2>
                                        <p class="tm-text"><span class="tm-white"><a href="https://journals.qucosa.de/array/article/download/3274/3092">Link to paper</a></span>
                                        </p>                                     
                                    </div>
                                    
                                    <div class="tm-img-gallery gallery-two">
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj2/fig3-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Three</span></h2>-->
                                                <p class="tm-figure-description">Workflow</p>
                                                <a href="img/projects/proj2/fig3.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                     <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj2/fig4-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Four</span></h2>-->
                                                <p class="tm-figure-description"> Female author names in the ICMC, SMC and NIME
                                                proceedings</p>
                                                <a href="img/projects/proj2/fig4.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj2/fig2-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Two</span></h2>-->
                                                <p class="tm-figure-description">Publication: ARRAY2021 – Diversity, pluralism – equity</p>
                                                <a href="img/projects/proj2/fig2.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                   
                                     <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj2/fig1-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>One</span></h2>-->
                                                <p class="tm-figure-description">Female vs unknown author names in the ICMC proceedings</p>
                                                <a href="img/projects/proj2/fig1.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                </div> <!-- .tm-img-gallery-container -->

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Background</h2>
                                                    <p class="tm-text">Although some of the first pioneers in Computer Science (e.g. <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Ada_Lovelace">Ada Lovelace</a> and <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Grace_Hopper">Grace Hopper</a>) were women, the field of Computer Music, as well as the <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Science,_technology,_engineering,_and_mathematics">STEM</a> fields in general, are still struggling with gender imbalance. In this project I wanted to explore the current status of this gender gap. <!-- As voiced by <a class="link-opacity-10" href="https://doi.org/10.1080/07494467.2016.1176764">Frida Abtan</a>: <i>“At conferences and workshops, there are always a few of us eyeing each other and asking ourselves: why are women still so under-represented in electronic music?” </i> This question is the overarching premise of this work. -->
                                                    </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Aim</h2>
                                                    <p class="tm-text">The goal of this project was to estimate the number of female authors publishing papers in the proceedings of the most important conferences in the Computer Music research field: <a class="link-opacity-10" href="https://smcnetwork.org/">Sound and Music Computing Conference (SMC)</a>, <a class="link-opacity-10" href="https://www.nime.org/">New Interfaces for Musical Expression (NIME)</a>, and <a class="link-opacity-10" href="https://www.computermusic.org/icmc-conference/">International Computer Music Conference (ICMC)</a>. 
                                                    </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>  
                                                  
                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                                    <h2 class="tm-text-title">Approach</h2>
                                                    <p class="tm-text">
                                                     In the absence of a readily available dataset, I constructed one by extracting information from external sources such as PDF proceedings, conference webpages, and BibTex files using custom Python scripts. To engineer the <i>'author gender'</i> feature, I utilized the genderize.io API for gender prediction ('male,' 'female,' or 'unknown').  Manual research further refined the data for names classified as 'unknown'. The data was then fitted to a model with Autoregressive Integrated Moving Average (ARIMA) errors.    
                                                     <br>
                                                    <br>
                                                    To further emphasize the the skewed distribution of author genders (the vast majority was still predominantly male), I converted the data into musical sounds using a technique called <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Sonification">sonification</a>.</p> 
                                                </div>
                                            </div>
                                        </div>
                                    </div>

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                                    <h2 class="tm-text-title">Insights and impact</h2>
                                                    <p class="tm-text">
                                                        For data until 2016, female author ratio was consistently below 20%. This tendency was largely consistent until year 2021. On the positive side, analysis of one of the proceedings (ICMC) suggested a tendency towards improvement in more recent years, with values ranging from 2.8% (in 1981) to 16.2% (in 2017). A regression model indicted a positive increase in female author names of 0.17% (± 0.1) per year (p < .001). 
                                                        <!--The first paper focused on the gender gap in proceedings up til 2016, with findings suggested values consistently below 20% female author names. The second paper followed up on the previous work, including data until 2021. Findings highlighted that the gender gap was persistent and that the numbers had not drastically changed since 2016. --> 

                                                        <br>
                                                        <br>
                                                        These findings were documented in two publications and disseminated through presentations at conferences and seminar series, sparking animated discussions within the research community. These discussions have contributed to the ongoing efforts towards achieveing greater inclusivity in the Computer Music field.

                                                        <br>
                                                        <br>



                                                    </p>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                    <div class="row">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Tools</h2>
                                                    <p class="tm-text">Python (numpy, pandas, <a class="link-opacity-10" href="https://genderize.io/">genderize</a>), LaTeX/BibTex, R (ggplot2, plotly), SuperCollider.</p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Methods</h2>
                                                    <p class="tm-text">Time series analysis using ARIMA models, text-based author gender classification, granular sound synthesis for data sonification.</p>     
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Links</h2>
                                                    <p class="tm-text"><a class="link-opacity-10" href="https://journals.qucosa.de/array/article/download/3274/3092">Publication (2021)</a>, <a class="link-opacity-10" href="https://www.researchgate.net/publication/320765100_Sonification_of_Women_in_Sound_and_Music_Computing_-_The_Sound_of_Female_Authorship_in_ICMC_SMC_and_NIME_Proceedings"> publication (2017)</a>, <a class="link-opacity-10" href="https://youtu.be/rEgMKINIU5E">sound examples (2021)</a>, <a class="link-opacity-10" href="https://www.youtube.com/playlist?list=PLdmT_JtSFfHZgghEI3PtKMo-OeVyDodYk">sound examples (2017)</a>.</p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>   
                                </div>                                 
                            
                        </div>         
                    </div>  
                </li>

                <!-- Page 3 Gallery Three -->
                <li>
                    <div class="cd-full-width">
                        <div class="container-fluid js-tm-page-content" data-page-no="3" data-page-type="gallery">                        
                            <div class="tm-img-gallery-container">
                                
                                <!-- Gallery Two pop up connected with JS code below -->
                                    
                                    <div class="tm-img-gallery-info-container">    
                                        <br>                        
                                        <h2 class="tm-text-title tm-gallery-title"><span class="tm-white">Music Creation by Example</span></h2>
                                        <p class="tm-text"><span class="tm-white"><a href="https://dl.acm.org/doi/10.1145/3313831.3376514">Link to paper</a></span>
                                        </p>                                     
                                    </div>

                                    <div class="tm-img-gallery gallery-three">
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj3/fig1-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>One</span></h2>-->
                                                <p class="tm-figure-description">GUI of the prototype system</p>
                                                <a href="img/projects/proj3/fig1.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj3/fig2-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Two</span></h2>-->
                                                <p class="tm-figure-description">Project workflow</p>
                                                <a href="img/projects/proj3/fig2.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj3/fig3-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Three</span></h2>-->
                                                <p class="tm-figure-description">Features suggested by user test participants (U) vs expert evaluators (E)</p>
                                                <a href="img/projects/proj3/fig3.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj3/fig4-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Four</span></h2>-->
                                                <p class="tm-figure-description">UI grid design</p>
                                                <a href="img/projects/proj3/fig4.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                </div> <!-- .tm-img-gallery-container -->
                                    
                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Background</h2>
                                                    <p class="tm-text">
                                                        Short online videos have become the dominating media on social platforms, but finding suitable music to accompany videos can be a challenging task, due to copyright constraints, limitations in search engines, and requirements for audio-editing expertise. A possible solution to this problem is to use AI music generation. This project focused on an interface paradigm that allows users to input a song to an AI engine and then interactively regenerate and mix AI-generated music based on the example song. 
                                                        </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Aim</h2>
                                                    <p class="tm-text">
                                                        The aim of this work was to explore novel interface solutions that would make music generation more intuitive and accessible for non-expert AI users. The project was carried out at <a class="link-opacity-10" href="https://research.adobe.com/about-adobe-research/">Adobe - Creative Intelligence Lab</a>, specifically targeting video creators. <!--  -- balancing automation and control -- -->
                                                    </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>  
                                                  
                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                                    <h2 class="tm-text-title">Approach</h2>
                                                    <p class="tm-text">                                                 
                                                    This project adopted an iterative design process informed by user studies. Initial pre-studies explored video creator needs and challenges, identifying potential solutions. Users were tasked with creating music for videos using an example song as a starting point. Feedback on early prototypes informed the development of a refined system, which was subsequently evaluated. Data, including user satisfaction ratings, time-on-task, and qualitative feedback, was collected from n=104 participants across multiple study phases. Both quantitative and qualitative analysis techniques were employed to extract valuable insights.
                                                    </p>
                                                </div>
                                            </div>
                                        </div>
                                    </div>

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                                    <h2 class="tm-text-title">Insights and impact</h2>
                                                    <p class="tm-text">

                                                    This project addressed a critical gap in video creation tools: simple and accessible music generation. Employing a user-centered approach, we developed a system enabling video creators to curate AI-generated music through an interactive interface. User studies demonstrated the system's effectiveness in meeting user needs; it was perceived as easy and enjoyable to use, required little learning time, and produced satisfying musical outcomes. This research highlights the importance of balancing automation and human agency in designing effective creative tools.
                                                    <br>
                                                    <br>
                                                    The work was published at the prestigious ACM CHI Conference on Human Factors in Computing Systems (24.3% acceptance rate), demonstrating its significance within the Human-Computer Interaction community. The paper has been cited 58 times. 


                                                    </p>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                    <div class="row">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Tools</h2>
                                                    <p class="tm-text">Python, R (ggplot2), <a class="link-opacity-10" href="https://www.ibm.com/watson">IBM Watson</a> (Watson Beat, AI-powered music composition), <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Electron_(software_framework)">Electron</a>, <a class="link-opacity-10" href="https://www.usertesting.com/">User testing</a>, Max/MSP, VSTs for audio generation (MIDI), Adobe XD. </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Methods</h2>
                                                    <p class="tm-text">
                                                        User testing, online questionnaires, thematic content analysis, brainstorming workshops, parallel prototyping, semi-structured interviews, think-aloud, evaluation of Human-AI interaction, expert evaluation, wireframing.</p>     
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Links</h2>
                                                    <p class="tm-text">
                                                        <a class="link-opacity-10" href="https://dl.acm.org/doi/10.1145/3313831.3376514">Publication</a>, 
                                                        <a class="link-opacity-10" href="https://dl.acm.org/doi/10.1145/3313831.3376514#sec-supp">files and data</a>, 
                                                        <a class="link-opacity-10" href="https://youtu.be/2a8DzysMZTc?feature=shared">video example</a>.
                                                    </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>   
                                </div>                                 
                        </div>         
                    </div>  
                </li>

                <!-- Page 4  -->
                <li>
                    <div class="cd-full-width">
                        <div class="container-fluid js-tm-page-content" data-page-no="4" data-page-type="gallery">                        
                            <div class="tm-img-gallery-container">
                                
                                <!-- Gallery Two pop up connected with JS code below -->
                                    
                                    <div class="tm-img-gallery-info-container">    
                                        <br>                  
                                        <h2 class="tm-text-title tm-gallery-title"><span class="tm-white">Multisensory Music Experiences for Children with Disabilities</span></h2>
                                        <p class="tm-text"><span class="tm-white"><a href="https://www.mdpi.com/2414-4088/6/7/55">Link to paper</a></span>
                                        </p>                                     
                                    </div>

                                    <div class="tm-img-gallery gallery-four">
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj5/fig1-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>One</span></h2>-->
                                                <p class="tm-figure-description">The Sound Forest installation </p>
                                                <a href="img/projects/proj5/fig1.jpeg">View more</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj5/fig4-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Three</span></h2>-->
                                                <p class="tm-figure-description">Plots of detected onsets and pitches triggered by user interaction</p>
                                                <a href="img/projects/proj5/fig4-tn.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                     <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj5/fig2-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Four</span></h2>-->
                                                <p class="tm-figure-description">Haptic Music Player developed to facilitate communication about musical haptics during the study</p>
                                                <a href="img/projects/proj5/fig2.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj5/fig3-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Two</span></h2>-->
                                                <p class="tm-figure-description"> Body maps illustrating where vibrations could be felt</p>
                                                <a href="img/projects/proj5/fig3.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                </div> <!-- .tm-img-gallery-container -->

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Background</h2>
                                                    <p class="tm-text">
                                                    Previous research has highlighted the importance of participatory design methods in developing digital musical instruments (see <a href="https://www.mdpi.com/2414-4088/3/3/57">my previous paper about ADMIs</a>). However, there is a significant gap in knowledge regarding the inclusion of pre-verbal children with Profound and Multiple Learning Disabilities (PMLD) in such design processes. By adapting participatory design methodologies for this population, this study aimed to support the customization and evaluation of the <a class="link-opacity-10" href="https://www.kth.se/hct/mid/research/smc/projects/sound-forest-1.897050"><i>Sound Forest</i></a> music installation, located at the <a class="link-opacity-10" href="https://scenkonstmuseet.se/?lang=en">Museum of Performing Arts </a> in Stockholm, Sweden. 

                                                    <!--We employed a case study approach utilizing in-depth qualitative and mixed methods with four PMLD students. This involved the application of Participatory Design with Proxies (PDwP) to assess how the students could be involved in the customization and evaluation of the design of a multisensory music experience involving music, light, and <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Haptic_perception">haptic</a> feedback (in this case, musical vibrations produced by vibrating shakers placed in the floor of the installation). -->
                                                    </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Aim</h2>
                                                    <p class="tm-text">The aim of this project was to create a customized multisensory experience tailored to the childrens’ needs, musical preferences, and abilities. A crucial aspect of the work was to explore effective methods for facilitating communication about music and haptic feedback. By understanding how these children interact with sound and music, this research seeks to contribute to the development of more inclusive and engaging musical experiences for all.
                                                    <!--
                                                    To engage the pre-verbal students in understanding and expressing their perception of musical vibrations, we used <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Augmentative_and_alternative_communication">Augmentative and Alternative Communication (AAC)</a> techniques, supplementing or replacing traiditional speech. 
                                                    -->
                                                </div>
                                            </div>
                                        </div>
                                    </div>  
                                                  
                                      <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Approach</h2>
                                            <p class="tm-text">
                                                The project involved a long-term collaboration with a student group, teacher, and teaching assistants at <a class="link-opacity-10" href="https://dibber.se/skola/rullens-sarskola/">Dibber Rullen School</a> and the <a class="link-opacity-10" href="https://scenkonstmuseet.se/?lang=en">Museum of Performing Arts</a>. 
                                                <!--These students do not yet have verbal communication skills, and they all have multifunctional physical challenges, with varying motor skills and moderate to severe intellectual challenges. -->

                                                 Employing a mixed-methods approach, we conducted physical characterization of the installation's vibrating platforms, collected sensor data, and observed student interactions. Additionally, teacher interviews, parent questionnaires, and music listening sessions provided valuable insights. To evaluate the final design, an experiment was conducted comparing different sensory conditions (seated vs. lying down, with and without haptic feedback). Data was collected through direct observation, video recordings and data logging, and post-experiment discussions.
                                            </p>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Insights and impact</h2>
                                            <p class="tm-text"> 
                                            Results suggested that the multisensory design was successful in terms of creating a relaxing and ever-changing sonic experience. User observations revealed diverse interaction strategies, emphasizing the importance of designing for individual differences. While the design promoted inclusivity to a certain extent, some limitations were also identified, informing future efforts to enhance accessibility. This study demonstrates the value of employing a multifaceted approach when developing multisensory experiences with and for pre-verbal children.

                                            <br>
                                            <br>
                                            Following a successful experiment, the Museum of Performing Arts (one of Sweden's most visited museums, with 265,421 visitors in 2023) integrated our multisensory design into their permanent <i>Sound Forest</i> exhibit. Since its inception in 2016, I have played a pivotal role in the ongoing evolution of the installation's haptic component. 
                                            <!--The installation will be open for visitors at least until 2026. -->
                                            </p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                                    <div class="row">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Tools</h2>
                                                    <p class="tm-text">Python, R, SuperCollider, Tombstone. </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Methods</h2>
                                                    <p class="tm-text">Acceleromenter and sensor data capture, Participatory Design with Proxies (PDwP), semi-structured interviews (stimulated recall), observational studies, questionnaires, body maps, micro phenomenological interviews, sound synthesis, evaluation methods.</p>     
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Links</h2>
                                                    <p class="tm-text">
                                                    <a class="link-opacity-10" href="https://www.mdpi.com/2414-4088/6/7/55">Publication (journal)</a>, <a class="link-opacity-10" href="https://doi.org/10.5281/zenodo.6464014"> data and files (including sound and video examples)</a>,  
                                                    <a class="link-opacity-10" href="https://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-331144">publication (conference)</a>, <a class="link-opacity-10" href="https://www.kth.se/hct/mid/research/smc/projects/sound-forest-1.897050">Sound Forest project page</a>.
                                                </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>   
                                </div>                                 
                            
                        </div>         
                    </div>  
                </li>

                <!-- Page 4  -->
                <li>
                    <div class="cd-full-width">
                        <div class="container-fluid js-tm-page-content" data-page-no="5" data-page-type="gallery">                        
                            <div class="tm-img-gallery-container">
                                
                                <!-- Gallery Two pop up connected with JS code below -->
                                    
                                    <div class="tm-img-gallery-info-container">    
                                        <br>           
                                        <h2 class="tm-text-title tm-gallery-title"><span class="tm-white">Making Music from Heartbeats</span></h2>
                                        <p class="tm-text"><span class="tm-white"><a href="https://hal.science/hal-03277425">Link to paper</a></span>
                                        </p>                                     
                                    </div>

                                    <div class="tm-img-gallery gallery-five">
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj4/fig1-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>One</span></h2>-->
                                                <p class="tm-figure-description">Results for patient vs medical team member</p>
                                                <a href="img/projects/proj4/fig1.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj4/fig2-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Two</span></h2>-->
                                                <p class="tm-figure-description">Distances in the pitch class helix of the spiral array</p>
                                                <a href="img/projects/proj4/fig2.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj4/fig3-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Three</span></h2>-->
                                                <p class="tm-figure-description">TFC (averaged over frequencies) between each patient and team member</p>
                                                <a href="img/projects/proj4/fig3.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj4/fig4-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Four</span></h2>-->
                                                <p class="tm-figure-description"> Interactive visualization of heartbeats and mean TFC</p>
                                                <a href="img/projects/proj4/fig4.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                     
                                </div> <!-- .tm-img-gallery-container -->

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Background</h2>
                                                    <p class="tm-text">During the COVID-19 pandemic, several attempts were made to make data more accessible using auditory representations (i.e., <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Sonification">sonifications</a> of data). The majority of these attempts focused on progression of the pandemic over time or aspects related to genomes and spike proteins. Little work in this context explored aspects related to the experiences of the patient and health workers directly impacted by COVID-19. In this project, we explored the potential of sonically representating heartbeats of a COVID-19 patient and a medical team using musical sonifications. A key focus of this work was to highlight how the medical team members came together when treating the patient, thus connecting to previous research on synchronization and <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Entrainment_(biomusicology)">entrainment</a>. 

                                                    </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Aim</h2>
                                                    <p class="tm-text">
                                                    The aim of this work was to sonify heart signals to reflect how a medical team comes together during a COVID-19 treatment. More specifically, the goal was to explore Time-Frequency Coherence (TFC) and heartbeat rhythms within this group, using sonic representations.  </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>  
                                                  
                             <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Approach</h2>
                                            <p class="tm-text">
                                                We used <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Heart_rate_variability">Heart Rate Variability</a> (HRV, a beat to beat variance measures), and Time Frequency Coherence (TFC, an estimation of spectral coherence, i.e. the degree of correlation between the spectral components of two signals in the joint time-frequency domain), to assess degree of similarity between two heart signals over different frequencies. TFC was used to evaluate HRV coupling between two individuals’ heart signals, which was also sonified and visualized. A rule-based system was implemented to map this relationship to sounds, based on consonance and dissonance in music. More specifically, the average TFC between the patient and respective medical team member was mapped to distance between pitches in the <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Spiral_array_model">spiral array</a>. As such, the system enabled creation of sounds representing the relationship between the heartsignals of the patient versus the medical team members. The sound generation system was evaluted through a web-based listening experiment with n=41 participants, with stimuli presented in two conditions: coherent versus incoherent signals (corresponding to consonant versus dissonant sounds). 
                                            </p>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Insights and impact</h2>
                                            <p class="tm-text">Results from the listening experiment suggested that the proposed mapping between TFC and consonance versus dissonance was successful in communicating low versus high coherence between heart signals, with an overall accuracy of 69% (significantly higher than chance). This work highlighted synergies between sound and heart signals through mapping between TFC of heart signals and harmonic tension and dissonance in music. These findings suggest that links between heart-and sound signals could be further explored through sonification to promote understanding of aspects related to cardiovascular health. </p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                                    <div class="row">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Tools</h2>
                                                    <p class="tm-text">MATLAB, Python, R, SuperCollider, Processing, OSC.</p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Methods</h2>
                                                    <p class="tm-text">Poisson regression analysis, chi-squared tests, interactive visualizations, evaluation experiments, sound synthesis.</p>     
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Links</h2>
                                                    <p class="tm-text">
                                                        <a class="link-opacity-10", href="https://hal.science/hal-03277425">Publication</a>,
                                                        <a class="link-opacity-10" href="https://drive.google.com/drive/folders/17z2m3xwkK-ySipwrU6UHoxXR5BxU9hmp"> files and data (including sound examples)</a>, 
                                                        <a class="link-opacity-10" href="https://cosmos.isd.kcl.ac.uk/">COSMOS and Heart.FM project pages</a>.</p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>   
                                </div>                                 
                            
                        </div>         
                        
                    </div> <!-- .cd-full-width -->
                </li>
            </ul> <!-- .cd-hero-slider -->
            
            <footer class="tm-footer">
            
                <div class="tm-social-icons-container text-xs-center">
                    <a href="https://github.com/emmenru" class="tm-social-link"><i class="fa fa-github"></i></a>
                    <a href="https://scholar.google.com/citations?user=0PvSz8cAAAAJ&hl=eng" class="tm-social-link"><i class="fa fa-google"></i></a>
                    <!--<a href="https://emserpics.tumblr.com/" class="tm-social-link"><i class="fa fa-twitter"></i></a>-->
                    <!--<a href="#" class="tm-social-link"><i class="fa fa-behance"></i></a>-->
                    <a href="https://www.linkedin.com/in/emmafrid" class="tm-social-link"><i class="fa fa-linkedin"></i></a>
                </div>
                
                <!--
                <p class="tm-copyright-text">Copyright &copy; 2017 Your Company 
                
                 - Design: Tooplate</p>
                -->

            </footer>
                    
        </div> <!-- .cd-hero -->
        

        <!-- Preloader, https://ihatetomatoes.net/create-custom-preloading-screen/ -->
        <div id="loader-wrapper">
            
            <div id="loader"></div>
            <div class="loader-section section-left"></div>
            <div class="loader-section section-right"></div>

        </div>
        
        <!-- load JS files -->
        <script src="js/jquery-1.11.3.min.js"></script>         <!-- jQuery (https://jquery.com/download/) -->
        <script src="https://www.atlasestateagents.co.uk/javascript/tether.min.js"></script> <!-- Tether for Bootstrap (http://stackoverflow.com/questions/34567939/how-to-fix-the-error-error-bootstrap-tooltips-require-tether-http-github-h) --> 
        <script src="js/bootstrap.min.js"></script>             <!-- Bootstrap js (v4-alpha.getbootstrap.com/) -->
        <script src="js/hero-slider-main.js"></script>          <!-- Hero slider (https://codyhouse.co/gem/hero-slider/) -->
        <script src="js/jquery.magnific-popup.min.js"></script> <!-- Magnific popup (http://dimsemenov.com/plugins/magnific-popup/) -->
        
        <script>

            function adjustHeightOfPage(pageNo) {

                var offset = 80;
                var pageContentHeight = 0;

                var pageType = $('div[data-page-no="' + pageNo + '"]').data("page-type");

                if( pageType != undefined && pageType == "gallery") {
                    pageContentHeight = $(".cd-hero-slider li:nth-of-type(" + pageNo + ") .tm-img-gallery-container").height();
                }
                else {
                    pageContentHeight = $(".cd-hero-slider li:nth-of-type(" + pageNo + ") .js-tm-page-content").height() + 20;
                }

                if($(window).width() >= 992) { offset = 120; }
                else if($(window).width() < 480) { offset = 40; }
               
                // Get the page height
                var totalPageHeight = $('.cd-slider-nav').height()
                                        + pageContentHeight + offset
                                        + $('.tm-footer').height();

                // Adjust layout based on page height and window height
                if(totalPageHeight > $(window).height()) 
                {
                    $('.cd-hero-slider').addClass('small-screen');
                    $('.cd-hero-slider li:nth-of-type(' + pageNo + ')').css("min-height", totalPageHeight + "px");
                }
                else 
                {
                    $('.cd-hero-slider').removeClass('small-screen');
                    $('.cd-hero-slider li:nth-of-type(' + pageNo + ')').css("min-height", "100%");
                }
            }

            /*
                Everything is loaded including images.
            */
            $(window).load(function(){

                adjustHeightOfPage(1); // Adjust page height

                /* Gallery One pop up
                -----------------------------------------*/
                $('.gallery-one').magnificPopup({
                    delegate: 'a', // child items selector, by clicking on it popup will open
                    type: 'image',
                    gallery:{enabled:true}                
                });
                
                /* Gallery Two pop up
                -----------------------------------------*/
                $('.gallery-two').magnificPopup({
                    delegate: 'a',
                    type: 'image',
                    gallery:{enabled:true}                
                });

                /* Gallery Three pop up
                -----------------------------------------*/
                $('.gallery-three').magnificPopup({
                    delegate: 'a',
                    type: 'image',
                    gallery:{enabled:true}                
                });

                /* Gallery Four pop up
                -----------------------------------------*/
                $('.gallery-four').magnificPopup({
                    delegate: 'a',
                    type: 'image',
                    gallery:{enabled:true}                
                });

                 /* Gallery Five pop up
                -----------------------------------------*/
                $('.gallery-five').magnificPopup({
                    delegate: 'a',
                    type: 'image',
                    gallery:{enabled:true}                
                });

                /* Collapse menu after click 
                -----------------------------------------*/
                $('#tmNavbar a').click(function(){
                    $('#tmNavbar').collapse('hide');

                    adjustHeightOfPage($(this).data("no")); // Adjust page height       
                });

                /* Browser resized 
                -----------------------------------------*/
                $( window ).resize(function() {
                    var currentPageNo = $(".cd-hero-slider li.selected .js-tm-page-content").data("page-no");
                    
                    // wait 3 seconds
                    setTimeout(function() {
                        adjustHeightOfPage( currentPageNo );
                    }, 1000);
                    
                });
        
                // Remove preloader (https://ihatetomatoes.net/create-custom-preloading-screen/)
                $('body').addClass('loaded');
                           
            });

            
        
            // DOM is ready
            $(function() {                
            });

        </script>            

</body>
</html>