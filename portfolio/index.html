<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Emma Frid &mdash; Portfolio</title>
<!--

Template 2086 Multi Color

http://www.tooplate.com/view/2086-multi-color

-->
    <!-- load stylesheets -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,400">  
    <!-- Google web font "Open Sans" -->
    <link rel="stylesheet" href="font-awesome-4.5.0/css/font-awesome.min.css">                
    <!-- Font Awesome -->
    <link rel="stylesheet" href="css/bootstrap.min.css">                                      
    <!-- Bootstrap style -->
    <link rel="stylesheet" href="css/hero-slider-style.css">                              
    <!-- Hero slider style (https://codyhouse.co/gem/hero-slider/) -->
    <link rel="stylesheet" href="css/magnific-popup.css">                                 
    <!-- Magnific popup style (http://dimsemenov.com/plugins/magnific-popup/) -->
    <link rel="stylesheet" href="css/tooplate-style.css">                                   

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
          <![endif]-->
</head>

    <body>
        
        <!-- Content -->
        <div class="cd-hero">

            <!-- Navigation -->        
            <div class="cd-slider-nav">
                <nav class="navbar">
                    <div class="tm-navbar-bg">
                        
                        <a class="navbar-brand text-uppercase fw-bold" href="#"><i class="fa fa-briefcase tm-brand-icon"></i>Emma FRID </a>

                        <button class="navbar-toggler hidden-lg-up" type="button" data-toggle="collapse" data-target="#tmNavbar">
                            &#9776;
                        </button>
                        <div class="collapse navbar-toggleable-md text-xs-center text-uppercase tm-navbar" id="tmNavbar">
                            <ul class="nav navbar-nav">
                                <li class="nav-item active selected">
                                    <a class="nav-link" href="#0" data-no="1">#1 <span class="sr-only">(current)</span></a>
                                </li>                                
                                <li class="nav-item">
                                    <a class="nav-link" href="#0" data-no="2">#2</a>
                                </li>
                                <li class="nav-item">
                                    <a class="nav-link" href="#0" data-no="3">#3</a>
                                </li>
                                <li class="nav-item">
                                    <a class="nav-link" href="#0" data-no="4">#4</a>
                                </li>
                                <li class="nav-item">
                                    <a class="nav-link" href="#0" data-no="5">#5</a>
                                </li>
                            </ul>
                        </div>                        
                    </div>

                </nav>
            </div> 

            <ul class="cd-hero-slider">

                <!-- Page 1 Gallery One -->
                <li class="selected">                    
                    <div class="cd-full-width">
                        <div class="container-fluid js-tm-page-content" data-page-no="1" data-page-type="gallery">                        
                            <div class="tm-img-gallery-container">

                                <!-- Gallery Two pop up connected with JS code below -->
                                    
                                    <!--<br>-->
                                    <div class="tm-img-gallery-info-container">     
                                        <br>
                                        <h2 class="tm-text-title tm-gallery-title"><span class="tm-white">Perception of Robot Sounds</span></h2>
                                        <p class="tm-text"><a href="https://link.springer.com/article/10.1007/s12369-021-00788-4">Link to full paper</a>
                                        </p>                                     
                                    </div>

                                    <div class="tm-img-gallery gallery-one">
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj1/fig1-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>One</span></h2>-->
                                                <p class="tm-figure-description">The NAO robot</p>
                                                <a href="img/projects/proj1/fig1.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj1/fig2-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Two</span></h2>-->
                                                <p class="tm-figure-description">Project workflow</p>
                                                <a href="img/projects/proj1/fig2.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj1/fig10-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Four</span></h2>-->
                                                <p class="tm-figure-description">Interaction graph for joyful stimuli</p>
                                                <a href="img/projects/proj1/fig10.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj1/fig9-tn.jpg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Three</span></h2>-->
                                                <p class="tm-figure-description">Mean ratings for joyful stimuli</p>
                                                <a href="img/projects/proj1/fig9.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                </div> <!-- .tm-img-gallery-container -->

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Background</h2>
                                                    <p class="tm-text">
                                                        It is well known that the sounds procuded by robots can have a significant effect on how the robot is perceived by a human counterpart. In this project we wanted to investigate if sounds inherent to robot movements (for example engine and motor sounds, glitches, etc.) can be processed in a way that enhances, rather than disturbs, emotion conveyed through robot gestures. For this purpose, we added synthesized sounds to the mechanical sounds produced by robots to improve communication. We refer to this augmentation and processing of existing robot sounds as <i>blended sonification</i>. <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Sonification">Sonification</a> is the use of non-speech audio to convey information or perceptualize data.
                                                        
                                                    </p>
                                            </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Aim</h2>
                                                    <p class="tm-text">The goal of this project was to design and evaluate non-speech sounds that can enhance and support the emotional expression of robot gestures. More specifically, the aim was to examine if mechanical sounds inherent to robot movements can be blended with carefully designed musical sounds to more efficiently communicate the emotions frustration, sadness, joy, and relaxation.</p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>  
                                                  
                            <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Approach</h2>
                                            <p class="tm-text">
                                            I led this project from start to finish, designing the experiment, collecting and cleaning the data, and conducting in-depth analysis to extract meaningful insights. The study consisted of two parts, Experiment 1, which focused on descriptions of sounds produced by expressive movements of a <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Nao_(robot)">NAO robot</a>, and Experiment 2, which focused on perceptual ratings of a) unprocessed mechanical robot sounds, versus b) processed (i.e. musically augmented) robot sounds. In Experiment 1, n=31 participants listened to the sounds and described them using free-form text annotations. Analysis of this data focused on aspects related to motion and emotion. In Experiment 2, the participants rated emotions conveyed by the sounds on a set of emotional scales. This data was analyzed using Two-Way Repeated Measures ANOVAs.
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Key insights</h2>
                                            <p class="tm-text">
                                            Experiment 1 revealed a disconnect between the robot's emotional expression and the sounds inherently produced by its movements. For example, the mechanical sounds that were inherently produced by the robot when performing a joyful gesture (a movement proven in previous experiments to be perceived as joyful by humans) actually sounded more as though the robot was frustrated. This kind of mismatch could potentially lead to miscommunication between robots and human counterparts. 
                                            <br>
                                            <br>   
                                            In Experiment 2, musical sounds were added to the mechanical robot sounds to try to counteract this effect. Analysis of quantitative ratings revealed that this technique successfully contributed to enhancement of the emotional message for sound models designed to convey frustration and joy. These findings offer valuable insights for robot sound design, particularly for gesticulating robots that produce sounds while they are moving. 
                                            <br>
                                            <br>    
                                            The results of this work were published in the International Journal of Social Robotics (five year impact factor 4.8, ranking among the 20 top Social Robotics journals). The paper has been cited 31 times.
                                            </p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                                    <div class="row">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Tools</h2>
                                                    <p class="tm-text">
                                                       R, Max/MSP, SPSS. 
                                                    </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Methods</h2>
                                                    <p class="tm-text">Analysis of variance (ANOVA) for statistical testing, text analysis techniques for data extraction, sound synthesis, subjective evaluation through user ratings.</p>     
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Links</h2>
                                                    <p class="tm-text">
                                                        <a class="link-opacity-10" href="https://link.springer.com/article/10.1007/s12369-021-00788-4">Publication</a>,
                                                        <a class="link-opacity-10" href="https://link.springer.com/article/10.1007/s12369-021-00788-4#availability-of-data-and-materials">files and data</a>, 
                                                        <a class="link-opacity-10" href="https://www.kth.se/hct/mid/research/smc/projects/sonao-1.895500">SONAO project page</a>. 

                                                    </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>   
                                </div>                                 
                            
                        </div>                                        
                    </div>                    
                </li>

                <!-- Page 2  -->
                <li>
                    <div class="cd-full-width">
                        <div class="container-fluid js-tm-page-content" data-page-no="2" data-page-type="gallery">                        
                            <div class="tm-img-gallery-container">
                                
                                <!-- Gallery Two pop up connected with JS code below -->                                    
                                    <div class="tm-img-gallery-info-container">    
                                        <br>                             
                                        <h2 class="tm-text-title tm-gallery-title"><span class="tm-white">The Gender Gap and the Computer Music Narrative</span></h2>
                                        <p class="tm-text"><span class="tm-white"><a href="https://journals.qucosa.de/array/article/download/3274/3092">Link to full paper</a></span>
                                        </p>                                     
                                    </div>
                                    
                                    <div class="tm-img-gallery gallery-two">
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj2/fig3-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Three</span></h2>-->
                                                <p class="tm-figure-description">Workflow</p>
                                                <a href="img/projects/proj2/fig3.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                     <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj2/fig4-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Four</span></h2>-->
                                                <p class="tm-figure-description"> Female author names in the ICMC, SMC and NIME
                                                proceedings</p>
                                                <a href="img/projects/proj2/fig4.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj2/fig2-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Two</span></h2>-->
                                                <p class="tm-figure-description">Publication: ARRAY2021 – Diversity, pluralism – equity</p>
                                                <a href="img/projects/proj2/fig2.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                   
                                     <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj2/fig1-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>One</span></h2>-->
                                                <p class="tm-figure-description">Female vs unknown author names in the ICMC proceedings</p>
                                                <a href="img/projects/proj2/fig1.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                </div> <!-- .tm-img-gallery-container -->

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Background</h2>
                                                    <p class="tm-text">Although some of the first pioneers in Computer Science were women (see e.g. <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Ada_Lovelace">Ada Lovelace</a> and <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Grace_Hopper">Grace Hopper</a>), the field of computer music, as well as the <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Science,_technology,_engineering,_and_mathematics">STEM</a> fields in general, are still struggling with gender balance. As voiced by <a class="link-opacity-10" href="https://doi.org/10.1080/07494467.2016.1176764">Frida Abtan</a>: <i>“At conferences and workshops, there are always a few of us eyeing each other and asking ourselves: why are women still so under-represented in electronic music?” </i> This question is the overarching premise of this work.
                                                    </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Aim</h2>
                                                    <p class="tm-text">The goal of this project was to estimate the number of female authors publishing papers in the proceedings of the most important conferences in the research field focused on Computer Music: <a class="link-opacity-10" href="https://smcnetwork.org/">Sound and Music Computing Conference (SMC)</a>, <a class="link-opacity-10" href="https://www.nime.org/">New Interfaces for Musical Expression (NIME)</a>, and <a class="link-opacity-10" href="https://www.computermusic.org/icmc-conference/">International Computer Music Conference (ICMC)</a>. 
                                                    </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>  
                                                  
                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                                    <h2 class="tm-text-title">Approach</h2>
                                                    <p class="tm-text">
                                                     In the absence of a readily available dataset, I constructed one by extracting information from external sources such as PDF proceedings, conference webpages, and BibTex files using custom Python scripts. To engineer the 'author gender' feature, I utilized the genderize.io API for prediction ('male,' 'female,' or 'unknown').  Manual research further refined the data for names classified as 'unknown'. The data was then fitted to a model with Autoregressive Integrated Moving Average (ARIMA) errors. 

                                                    To emphasize the the skewed distribution of author genders (predominantly male names), I converted the data into audible representations using <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Sonification">sonification</a>; I synthesized musical sounds that illustrated the gender gap. </p> 
                                                </div>
                                            </div>
                                        </div>
                                    </div>

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                                    <h2 class="tm-text-title">Key insights</h2>
                                                    <p class="tm-text">
                                                        The project's findings are documented in two publications (2017, 2021). The work has been actively disseminated through presentations at conferences and seminar series, sparking animated discussions within the research community. These discussions highlight the importance of gender balance, contributing to ongoing efforts towards greater inclusivity in the field.

                                                        <br>
                                                        <br>

                                                        The first paper focuses on the gender gap in proceedings up til 2016, with findings suggested values consistently below 20% female author names. The second paper followed up on the previous work, including data until 2021. Findings highlighted that the gender gap was persistent and that the numbers had not drastically changed since 2016. However, temporal analysis of predicted genders of unique author names in the ICMC proceedings suggested a tendency towards higher percentages of female names in more recent years, with values ranging from 2.8% (1981) to 16.2% (2017), and an overall of 10.4% female names. The regression model indicted a positive increase in female author names of 0.17% (± 0.1) per year (p < .001). 

                                                    </p>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                    <div class="row">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Tools</h2>
                                                    <p class="tm-text">Python (numpy, pandas, <a class="link-opacity-10" href="https://genderize.io/">genderize</a>), LaTeX/BibTex, R (ggplot2, plotly), SuperCollider.</p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Methods</h2>
                                                    <p class="tm-text">Time series analysis using ARIMA models, text-based author gender classification, granular sound synthesis for data sonification.</p>     
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Links</h2>
                                                    <p class="tm-text"><a class="link-opacity-10" href="https://journals.qucosa.de/array/article/download/3274/3092">Publication (2021)</a>, <a class="link-opacity-10" href="https://www.researchgate.net/publication/320765100_Sonification_of_Women_in_Sound_and_Music_Computing_-_The_Sound_of_Female_Authorship_in_ICMC_SMC_and_NIME_Proceedings"> publication (2017)</a>, <a class="link-opacity-10" href="https://youtu.be/rEgMKINIU5E">sound examples (2021)</a>, <a class="link-opacity-10" href="https://www.youtube.com/playlist?list=PLdmT_JtSFfHZgghEI3PtKMo-OeVyDodYk">sound examples (2017)</a>.</p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>   
                                </div>                                 
                            
                        </div>         
                    </div>  
                </li>

                <!-- Page 3 Gallery Three -->
                <li>
                    <div class="cd-full-width">
                        <div class="container-fluid js-tm-page-content" data-page-no="3" data-page-type="gallery">                        
                            <div class="tm-img-gallery-container">
                                
                                <!-- Gallery Two pop up connected with JS code below -->
                                    
                                    <div class="tm-img-gallery-info-container">    
                                        <br>                        
                                        <h2 class="tm-text-title tm-gallery-title"><span class="tm-white">Music Creation by Example</span></h2>
                                        <p class="tm-text"><span class="tm-white"><a href="https://dl.acm.org/doi/10.1145/3313831.3376514">Link to full paper</a></span>
                                        </p>                                     
                                    </div>

                                    <div class="tm-img-gallery gallery-three">
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj3/fig1-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>One</span></h2>-->
                                                <p class="tm-figure-description">GUI of the prototype system</p>
                                                <a href="img/projects/proj3/fig1.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj3/fig2-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Two</span></h2>-->
                                                <p class="tm-figure-description">Project workflow</p>
                                                <a href="img/projects/proj3/fig2.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj3/fig3-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Three</span></h2>-->
                                                <p class="tm-figure-description">Features suggested by user test participants (U) vs expert evaluators (E)</p>
                                                <a href="img/projects/proj3/fig3.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj3/fig4-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Four</span></h2>-->
                                                <p class="tm-figure-description">UI grid design</p>
                                                <a href="img/projects/proj3/fig4.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                </div> <!-- .tm-img-gallery-container -->
                                    
                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Background</h2>
                                                    <p class="tm-text">
                                                        Short online videos have become the dominating media on social platforms. However, finding suitable music to accompany videos can be a challenging task to some video creators, due to copyright constraints, limitations in search engines, and required audio-editing expertise. A possible solution to the above mentioned problems is to use AI music generation. In this work, we presented a User Interface (UI) paradigm that allows users to input a song to an AI engine and then interactively regenerate and mix AI-generated music based on the example song. This project was carried out in collaboration with the <a class="link-opacity-10" href="https://research.adobe.com/about-adobe-research/">Adobe - Creative Intelligence Lab</a> in San Francisco.</p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Aim</h2>
                                                    <p class="tm-text">
                                                        The aim of this work was to we explore new interface solutions that bridges AI solutions with non-expert users, balancing between automation and control, thereby making music generation more straightforward and easily accessible. 
                                                    </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>  
                                                  
                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                                    <h2 class="tm-text-title">Approach</h2>
                                                    <p class="tm-text">                                                 
                                                    This project adopted an iterative design process informed by user studies throughout the development cycle. We conducted a total of three pre-studies: 

                                                    1) <i>Formative interviews</i> to explore video creator needs and challenges. 2) <i>Brainstorming workshop</i> to identify potential solutions. 3) <i>Prototype usability testing</i> to gather feedback on initial prototype iterations.
                                                    <br> 
                                                    <br>
                                                    Following these pre-studies, we evaluated a refined prototype system with video creators. Participants created music for videos using the system, inputting an example song as starting point, and we collected data through: 1) <i>Semi-structured interviews</i> to probe user experience and suggestions for improvement, and 2) <i>Evaluation Questionnaires</i> to gather quantitative feedback on satisfaction and usability.
                                                    <br>
                                                    <br>
                                                    Throughout the project, a total of n=104 people participated in the user studies at different stages. Both quantitative and qualitative data analysis techniques were employed to extract valuable insights that guided further design iterations and ultimately led to the final system design.

                                                    </p>
                                                </div>
                                            </div>
                                        </div>
                                    </div>

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                                    <h2 class="tm-text-title">Key insights</h2>
                                                    <p class="tm-text">

                                                    This project addressed a critical user need in the video creation space: the lack of simple and accessible music generation tools. Through a user-centered design approach, we developed a music generation system based on <i>“creation by example”</i> that allows video creators to curate AI-generated music using an interactive and iterative mixing interface. Findings indicate that the designed system succeeded in meeting user needs; it was perceived as easy and enjoyable to use, require little learning time, and produced satisfying musical outcomes for the majority of the participants. This innovative UI paradigm empowers video creators by enabling efficient music creation for video without time-consuming search and editing processes. Understanding the user preference for a balance between AI control and human input is crucial for designing effective creative tools. This research informs the development of systems that empower users with both AI assistance and the freedom to personalize their creative workflow.
                                                    <br>
                                                    <br>
                                                    This work was published at the prestigious ACM CHI Conference on Human Factors in Computing Systems (24.3% acceptance rate), demonstrating its significance within the Human-Computer Interaction community. The paper has been cited 56 times. 


                                                    </p>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                    <div class="row">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Tools</h2>
                                                    <p class="tm-text">Python, R (ggplot2), <a class="link-opacity-10" href="https://www.ibm.com/watson">IBM Watson</a> (Watson Beat, AI-powered music composition), <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Electron_(software_framework)">Electron</a>, <a class="link-opacity-10" href="https://www.usertesting.com/">User testing</a>, Max/MSP, VSTs for audio generation (MIDI), Adobe XD. </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Methods</h2>
                                                    <p class="tm-text">
                                                        User testing, online questionnaires, thematic content analysis, brainstorming workshops, parallel prototyping, semi-structured interviews, think-aloud, evaluation of Human-AI interaction, expert evaluation, wireframing.</p>     
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Links</h2>
                                                    <p class="tm-text">
                                                        <a class="link-opacity-10" href="https://dl.acm.org/doi/10.1145/3313831.3376514">Publication</a>, 
                                                        <a class="link-opacity-10" href="https://dl.acm.org/doi/10.1145/3313831.3376514#sec-supp">files and data</a>, 
                                                        <a class="link-opacity-10" href="https://youtu.be/2a8DzysMZTc?feature=shared">video example</a>.
                                                    </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>   
                                </div>                                 
                        </div>         
                    </div>  
                </li>

                <!-- Page 4  -->
                <li>
                    <div class="cd-full-width">
                        <div class="container-fluid js-tm-page-content" data-page-no="4" data-page-type="gallery">                        
                            <div class="tm-img-gallery-container">
                                
                                <!-- Gallery Two pop up connected with JS code below -->
                                    
                                    <div class="tm-img-gallery-info-container">    
                                        <br>                  
                                        <h2 class="tm-text-title tm-gallery-title"><span class="tm-white">Customizing and Evaluating Accessible Multisensory Music Experiences with Pre-Verbal Children</span></h2>
                                        <p class="tm-text"><span class="tm-white"><a href="https://www.mdpi.com/2414-4088/6/7/55">Link to full paper</a></span>
                                        </p>                                     
                                    </div>

                                    <div class="tm-img-gallery gallery-four">
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj5/fig1-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>One</span></h2>-->
                                                <p class="tm-figure-description">The Sound Forest installation </p>
                                                <a href="img/projects/proj5/fig1.jpeg">View more</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj5/fig4-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Three</span></h2>-->
                                                <p class="tm-figure-description">Plots of detected onsets and pitches triggered by user interaction</p>
                                                <a href="img/projects/proj5/fig4-tn.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                     <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj5/fig2-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Four</span></h2>-->
                                                <p class="tm-figure-description">Haptic Music Player developed to facilitate communication about musical haptics during the study</p>
                                                <a href="img/projects/proj5/fig2.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj5/fig3-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Two</span></h2>-->
                                                <p class="tm-figure-description"> Body maps illustrating where vibrations could be felt</p>
                                                <a href="img/projects/proj5/fig3.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                </div> <!-- .tm-img-gallery-container -->

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Background</h2>
                                                    <p class="tm-text">

                                                    Existing research emphasizes the value of participatory design methods in developing <a class="link-opacity-10" href="https://www.mdpi.com/2414-4088/3/3/57">Accessible Digital Musical Instruments (ADMIs)</a> for electronic music, inclusive music practices, and music therapy settings. However, limited work exists when it comes to the inclusion of pre-verbal children with Profound and Multiple Learning Disabilities (PMLD) in such design processes. This study investigated how participatory design methodologies could be adapted to involve pre-verbal children with PMLD in the customization and evaluation of our music installation <a class="link-opacity-10" href="https://www.kth.se/hct/mid/research/smc/projects/sound-forest-1.897050">Sound Forest</a>, situated at <a class="link-opacity-10" href="https://scenkonstmuseet.se/?lang=en">Museum of Performing Arts </a> (Scenkonstmuséet) in Stockholm, Sweden. We employed a case study approach utilizing in-depth qualitative and mixed methods with four PMLD students. This involved the application of Participatory Design with Proxies (PDwP) to assess how the students could be involved in the customization and evaluation of the design of a multisensory music experience involving music, light, and <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Haptic_perception">haptic</a> feedback (in this case, musical vibrations produced by vibrating shakers placed in the floor of the installation). 
                                                    </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Aim</h2>
                                                    <p class="tm-text">The aim of this project was to create a customized multisensory experience tailored to the students’ needs, musical preferences, and abilities. A crucial aspect of the work was to explore effective methods for facilitating communication about music and haptic feedback. To engage the pre-verbal students in understanding and expressing their perception of musical vibrations, we used <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Augmentative_and_alternative_communication">Augmentative and Alternative Communication (AAC)</a> techniques, supplementing or replacing traiditional speech.
                                                </div>
                                            </div>
                                        </div>
                                    </div>  
                                                  
                                      <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Approach</h2>
                                            <p class="tm-text">
                                                This project involved a long-term collaboration with a student group, teacher, and teaching assistants at <a class="link-opacity-10" href="https://dibber.se/skola/rullens-sarskola/">Dibber Rullen School</a> (Solna, Sweden), and the <a class="link-opacity-10" href="https://scenkonstmuseet.se/?lang=en">Museum of Performing Arts </a> (Stockholm, Sweden). The students that we collaborated with are mostly pre-verbal, meaning that they do not yet have verbal communication skills, and they all have multifunctional physical challenges, with varying motor skills and moderate to severe intellectual challenges. 


                                                A mixed-methods approach informed the design of a multisensory experience for the museum's "Sound Forest" exhibit. This included physical characterization of vibrating platforms in the installation and collection of sensor data, as well as observational studies, teacher interviews, parent questionnaires, and music listening sessions with students.

                                                The final design was evaluated through an experiment with the students exploring the installation under four conditions: seated vs. lying down, with and without haptic feedback. AAC tools facilitated communication about their experiences, and log/video data captured user interactions with sensors. A semi-structured group interview with the teacher and assistants, using stimulated-recall methodology, provided additional insights.

                                            </p>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Key insights</h2>
                                            <p class="tm-text"> Results suggested that the multisensory design was successful in terms of creating a relaxing and ever-changing sonic experience, with a constant yet not overwhelming vibration coming from the haptic floor. Exploration of log and video revealed a wide range of strategies employed by the children to engage with the installation. This highlights the importance of considering individual differences in future design iterations. We also identified limitations in terms of the accessibility of the current multisensory design. These findings will inform future efforts to enhance inclusivity and cater to a broader range of needs. Finally, the project demonstrates the effectiveness using a multifaceted variety of qualitative and quantitative methods to arrive at more informed conclusions when applying a <i>Participatory Design with Proxies</i> methodology to gain comprehensive insights into user experience. This work sheds light on methodological and design considerations that should be taken into account when developing multisensory experiences informed by pre-verbal children.

                                            <br>
                                            <br>
                                            
                                            Following a successful user experiment, the Museum of Performing Arts (which is one of Sweden's most visited museums, with 265 421 visitors in total in 2023) opted to integrate our multisensory design into their permanent "Sound Forest" exhibit. Since the collaboration with the museum was initiated in 2016, I've played a key role in the ongoing design evolution of the haptic component, utilizing data analysis and user interaction considerations to create a core element that continues to engage visitors. The installation will be open for visitors at least until 2026.  
                                            </p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                                    <div class="row">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Tools</h2>
                                                    <p class="tm-text">Python, R, SuperCollider, Tombstone. </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Methods</h2>
                                                    <p class="tm-text">Acceleromenter data capture, sensor data capture, Participatory Design with Proxies (PDwP), semi-structured interviews (stimulated recall), observational studies, questionnaires, body maps, micro phenomenological interviews, sound synthesis, evaluation methods.</p>     
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Links</h2>
                                                    <p class="tm-text">
                                                    <a class="link-opacity-10" href="https://www.mdpi.com/2414-4088/6/7/55">Publication (journal)</a>, <a class="link-opacity-10" href="https://doi.org/10.5281/zenodo.6464014"> data and files (including sound and video examples)</a>,  
                                                    <a class="link-opacity-10" href="https://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-331144">publication (conference)</a>, <a class="link-opacity-10" href="https://www.kth.se/hct/mid/research/smc/projects/sound-forest-1.897050">Sound Forest project page</a>.
                                                </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>   
                                </div>                                 
                            
                        </div>         
                    </div>  
                </li>

                <!-- Page 4  -->
                <li>
                    <div class="cd-full-width">
                        <div class="container-fluid js-tm-page-content" data-page-no="5" data-page-type="gallery">                        
                            <div class="tm-img-gallery-container">
                                
                                <!-- Gallery Two pop up connected with JS code below -->
                                    
                                    <div class="tm-img-gallery-info-container">    
                                        <br>           
                                        <h2 class="tm-text-title tm-gallery-title"><span class="tm-white">Sonification of Heart Signals</span></h2>
                                        <p class="tm-text"><span class="tm-white"><a href="https://hal.science/hal-03277425">Link to full paper</a></span>
                                        </p>                                     
                                    </div>

                                    <div class="tm-img-gallery gallery-five">
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj4/fig1-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>One</span></h2>-->
                                                <p class="tm-figure-description">Results for patient versus a medical team member</p>
                                                <a href="img/projects/proj4/fig1.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj4/fig2-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Two</span></h2>-->
                                                <p class="tm-figure-description">Distances in the pitch class helix of the spiral array</p>
                                                <a href="img/projects/proj4/fig2.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj4/fig3-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Three</span></h2>-->
                                                <p class="tm-figure-description">TFC (averaged over frequencies) between each patient and team member</p>
                                                <a href="img/projects/proj4/fig3.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj4/fig4-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Four</span></h2>-->
                                                <p class="tm-figure-description"> Visualization of heartbeats and mean TFC</p>
                                                <a href="img/projects/proj4/fig4.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                     
                                </div> <!-- .tm-img-gallery-container -->

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Background</h2>
                                                    <p class="tm-text">During the COVID-19 pandemic, several attempts were made to make data more accessible using auditory representations (i.e., <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Sonification">sonifications</a> of data). The majority of these attempts focused on progression of the pandemic over time or aspects related to genomes and spike proteins. Little work in this context explored aspects related to the experiences of the patient and health workers directly impacted by COVID-19. In this project, we explored the potential of sonically representating heartbeats of a COVID-19 patient and a medical team using musical sonifications. A key focus of this work was to highlight how the medical team members came together when treating the patient, thus connecting to previous research on synchronization and <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Entrainment_(biomusicology)">entrainment</a>. 

                                                    </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Aim</h2>
                                                    <p class="tm-text">
                                                    The aim of this work was to sonify heart signals to reflect how a medical team comes together during a COVID-19 treatment. More specifically, the goal was to explore Time-Frequency Coherence (TFC) and heartbeat rhythms within this group, using sonic representations.  </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>  
                                                  
                             <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Approach</h2>
                                            <p class="tm-text">
                                                We used <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Heart_rate_variability">Heart Rate Variability</a> (HRV, a beat to beat variance measures), and Time Frequency Coherence (TFC, an estimation of spectral coherence, i.e. the degree of correlation between the spectral components of two signals in the joint time-frequency domain), to assess degree of similarity between two heart signals over different frequencies. TFC was used to evaluate HRV coupling between two individuals’ heart signals, which was also sonified and visualized. A rule-based system was implemented to map this relationship to sounds, based on consonance and dissonance in music. More specifically, the average TFC between the patient and respective medical team member was mapped to distance between pitches in the <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Spiral_array_model">spiral array</a>. As such, the system enabled creation of sounds representing the relationship between the heartsignals of the patient versus the medical team members. The sound generation system was evaluted through a web-based listening experiment with n=41 participants, with stimuli presented in two conditions: coherent versus incoherent signals (corresponding to consonant versus dissonant sounds). 
                                            </p>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Key insights</h2>
                                            <p class="tm-text">Results from the listening experiment suggested that the proposed mapping between TFC and consonance versus dissonance was successful in communicating low versus high coherence between heart signals, with an overall accuracy of 69% (significantly higher than chance). This work highlighted synergies between sound and heart signals through mapping between TFC of heart signals and harmonic tension and dissonance in music. These findings suggest that links between heart-and sound signals could be further explored through sonification to promote understanding of aspects related to cardiovascular health. </p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                                    <div class="row">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Tools</h2>
                                                    <p class="tm-text">MATLAB, Python, R, SuperCollider, Processing, OSC.</p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Methods</h2>
                                                    <p class="tm-text">Poisson regression analysis, chi-squared tests, interactive visualizations, evaluation experiments, sound synthesis.</p>     
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Links</h2>
                                                    <p class="tm-text">
                                                        <a class="link-opacity-10", href="https://hal.science/hal-03277425">Publication</a>,
                                                        <a class="link-opacity-10" href="https://drive.google.com/drive/folders/17z2m3xwkK-ySipwrU6UHoxXR5BxU9hmp"> files and data (including sound examples)</a>, 
                                                        <a class="link-opacity-10" href="https://cosmos.isd.kcl.ac.uk/">COSMOS and Heart.FM project pages</a>.</p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>   
                                </div>                                 
                            
                        </div>         
                        
                    </div> <!-- .cd-full-width -->
                </li>
            </ul> <!-- .cd-hero-slider -->
            
            <footer class="tm-footer">
            
                <div class="tm-social-icons-container text-xs-center">
                    <a href="https://github.com/emmenru" class="tm-social-link"><i class="fa fa-github"></i></a>
                    <a href="https://scholar.google.com/citations?user=0PvSz8cAAAAJ&hl=eng" class="tm-social-link"><i class="fa fa-google"></i></a>
                    <!--<a href="https://emserpics.tumblr.com/" class="tm-social-link"><i class="fa fa-twitter"></i></a>-->
                    <!--<a href="#" class="tm-social-link"><i class="fa fa-behance"></i></a>-->
                    <a href="https://www.linkedin.com/in/emmafrid" class="tm-social-link"><i class="fa fa-linkedin"></i></a>
                </div>
                
                <!--
                <p class="tm-copyright-text">Copyright &copy; 2017 Your Company 
                
                 - Design: Tooplate</p>
                -->

            </footer>
                    
        </div> <!-- .cd-hero -->
        

        <!-- Preloader, https://ihatetomatoes.net/create-custom-preloading-screen/ -->
        <div id="loader-wrapper">
            
            <div id="loader"></div>
            <div class="loader-section section-left"></div>
            <div class="loader-section section-right"></div>

        </div>
        
        <!-- load JS files -->
        <script src="js/jquery-1.11.3.min.js"></script>         <!-- jQuery (https://jquery.com/download/) -->
        <script src="https://www.atlasestateagents.co.uk/javascript/tether.min.js"></script> <!-- Tether for Bootstrap (http://stackoverflow.com/questions/34567939/how-to-fix-the-error-error-bootstrap-tooltips-require-tether-http-github-h) --> 
        <script src="js/bootstrap.min.js"></script>             <!-- Bootstrap js (v4-alpha.getbootstrap.com/) -->
        <script src="js/hero-slider-main.js"></script>          <!-- Hero slider (https://codyhouse.co/gem/hero-slider/) -->
        <script src="js/jquery.magnific-popup.min.js"></script> <!-- Magnific popup (http://dimsemenov.com/plugins/magnific-popup/) -->
        
        <script>

            function adjustHeightOfPage(pageNo) {

                var offset = 80;
                var pageContentHeight = 0;

                var pageType = $('div[data-page-no="' + pageNo + '"]').data("page-type");

                if( pageType != undefined && pageType == "gallery") {
                    pageContentHeight = $(".cd-hero-slider li:nth-of-type(" + pageNo + ") .tm-img-gallery-container").height();
                }
                else {
                    pageContentHeight = $(".cd-hero-slider li:nth-of-type(" + pageNo + ") .js-tm-page-content").height() + 20;
                }

                if($(window).width() >= 992) { offset = 120; }
                else if($(window).width() < 480) { offset = 40; }
               
                // Get the page height
                var totalPageHeight = $('.cd-slider-nav').height()
                                        + pageContentHeight + offset
                                        + $('.tm-footer').height();

                // Adjust layout based on page height and window height
                if(totalPageHeight > $(window).height()) 
                {
                    $('.cd-hero-slider').addClass('small-screen');
                    $('.cd-hero-slider li:nth-of-type(' + pageNo + ')').css("min-height", totalPageHeight + "px");
                }
                else 
                {
                    $('.cd-hero-slider').removeClass('small-screen');
                    $('.cd-hero-slider li:nth-of-type(' + pageNo + ')').css("min-height", "100%");
                }
            }

            /*
                Everything is loaded including images.
            */
            $(window).load(function(){

                adjustHeightOfPage(1); // Adjust page height

                /* Gallery One pop up
                -----------------------------------------*/
                $('.gallery-one').magnificPopup({
                    delegate: 'a', // child items selector, by clicking on it popup will open
                    type: 'image',
                    gallery:{enabled:true}                
                });
                
                /* Gallery Two pop up
                -----------------------------------------*/
                $('.gallery-two').magnificPopup({
                    delegate: 'a',
                    type: 'image',
                    gallery:{enabled:true}                
                });

                /* Gallery Three pop up
                -----------------------------------------*/
                $('.gallery-three').magnificPopup({
                    delegate: 'a',
                    type: 'image',
                    gallery:{enabled:true}                
                });

                /* Gallery Four pop up
                -----------------------------------------*/
                $('.gallery-four').magnificPopup({
                    delegate: 'a',
                    type: 'image',
                    gallery:{enabled:true}                
                });

                 /* Gallery Five pop up
                -----------------------------------------*/
                $('.gallery-five').magnificPopup({
                    delegate: 'a',
                    type: 'image',
                    gallery:{enabled:true}                
                });

                /* Collapse menu after click 
                -----------------------------------------*/
                $('#tmNavbar a').click(function(){
                    $('#tmNavbar').collapse('hide');

                    adjustHeightOfPage($(this).data("no")); // Adjust page height       
                });

                /* Browser resized 
                -----------------------------------------*/
                $( window ).resize(function() {
                    var currentPageNo = $(".cd-hero-slider li.selected .js-tm-page-content").data("page-no");
                    
                    // wait 3 seconds
                    setTimeout(function() {
                        adjustHeightOfPage( currentPageNo );
                    }, 1000);
                    
                });
        
                // Remove preloader (https://ihatetomatoes.net/create-custom-preloading-screen/)
                $('body').addClass('loaded');
                           
            });

            
        
            // DOM is ready
            $(function() {                
            });

        </script>            

</body>
</html>