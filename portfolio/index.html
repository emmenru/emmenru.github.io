<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>EF &mdash; Portfolio</title>
<!--

Template 2086 Multi Color

http://www.tooplate.com/view/2086-multi-color

-->
    <!-- load stylesheets -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,400">  
    <!-- Google web font "Open Sans" -->
    <link rel="stylesheet" href="font-awesome-4.5.0/css/font-awesome.min.css">                
    <!-- Font Awesome -->
    <link rel="stylesheet" href="css/bootstrap.min.css">                                      
    <!-- Bootstrap style -->
    <link rel="stylesheet" href="css/hero-slider-style.css">                              
    <!-- Hero slider style (https://codyhouse.co/gem/hero-slider/) -->
    <link rel="stylesheet" href="css/magnific-popup.css">                                 
    <!-- Magnific popup style (http://dimsemenov.com/plugins/magnific-popup/) -->
    <link rel="stylesheet" href="css/tooplate-style.css">                                   

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
          <![endif]-->
</head>

    <body>
        
        <!-- Content -->
        <div class="cd-hero">

            <!-- Navigation -->        
            <div class="cd-slider-nav">
                <nav class="navbar">
                    <div class="tm-navbar-bg">
                        
                        <a class="navbar-brand text-uppercase fw-bold" href="#"><i class="fa fa-briefcase tm-brand-icon"></i>EF &mdash; Portfolio</a>

                        <button class="navbar-toggler hidden-lg-up" type="button" data-toggle="collapse" data-target="#tmNavbar">
                            &#9776;
                        </button>
                        <div class="collapse navbar-toggleable-md text-xs-center text-uppercase tm-navbar" id="tmNavbar">
                            <ul class="nav navbar-nav">
                                <li class="nav-item active selected">
                                    <a class="nav-link" href="#0" data-no="1">Project #1 <span class="sr-only">(current)</span></a>
                                </li>                                
                                <li class="nav-item">
                                    <a class="nav-link" href="#0" data-no="2">Project #2</a>
                                </li>
                                <li class="nav-item">
                                    <a class="nav-link" href="#0" data-no="3">Project #3</a>
                                </li>
                                <li class="nav-item">
                                    <a class="nav-link" href="#0" data-no="4">Project #4</a>
                                </li>
                                <li class="nav-item">
                                    <a class="nav-link" href="#0" data-no="5">Project #5</a>
                                </li>
                            </ul>
                        </div>                        
                    </div>

                </nav>
            </div> 

            <ul class="cd-hero-slider">

                <!-- Page 1 Gallery One -->
                <li class="selected">                    
                    <div class="cd-full-width">
                        <div class="container-fluid js-tm-page-content" data-page-no="1" data-page-type="gallery">                        
                            <div class="tm-img-gallery-container">
                                <div class="tm-img-gallery gallery-one">
                                <!-- Gallery Two pop up connected with JS code below -->
                                    
                                    <div class="tm-img-gallery-info-container">                                    
                                        <h2 class="tm-text-title tm-gallery-title"><span class="tm-white">Perception of Robot Sounds</span></h2>
                                        <p class="tm-text">Perceptual Evaluation of Blended Sonification of Mechanical Robot Sounds Produced by Emotionally Expressive Gestures
                                        </p>                                     
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj1/fig1-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>One</span></h2>-->
                                                <p class="tm-figure-description">The NAO robot</p>
                                                <a href="img/projects/proj1/fig1.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj1/fig2-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Two</span></h2>-->
                                                <p class="tm-figure-description">Project workflow</p>
                                                <a href="img/projects/proj1/fig2.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj1/fig10-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Four</span></h2>-->
                                                <p class="tm-figure-description">Interaction graph for joyful stimuli</p>
                                                <a href="img/projects/proj1/fig10.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj1/fig9-tn.jpg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Three</span></h2>-->
                                                <p class="tm-figure-description">Mean ratings for joyful stimuli</p>
                                                <a href="img/projects/proj1/fig9.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                </div> <!-- .tm-img-gallery-container -->

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Background</h2>
                                                    <p class="tm-text">
                                                        Sounds inherent to robot movements can influence how robot gestures are perceived. In this project, we wanted to investigate if mechanical robot sounds could be processed in a way that enhances, rather than disturbs, the emotion conveyed through robot gestures. We refer to this augmentation and processing of existing robot sounds as a <i>blended sonification</i>. <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Sonification">Sonification</a> is the use of non-speech audio to convey information or perceptualize data.
                                                        
                                                    </p>
                                            </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Aim</h2>
                                                    <p class="tm-text">The goal of this project was to design and evaluate non-speech sounds that can enhance and support the emotional expression of robot gestures.</p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>  
                                                  
                            <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Approach</h2>
                                            <p class="tm-text">
                                            This project involved everything from experimental design to conducting experiments for data collection, data cleaning, and analysis of the collected data. The study consisted of two parts, Experiment 1, focusing on descriptions of sounds produced by expressive movements of a <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Nao_(robot)">NAO robot</a>, and Experiment 2, focusing on perceptual ratings of these sounds and blended sonifications thereof, i.e. robot sounds that had been processed and augmented with additional musical sounds. We adopted a mixed-methods approach combining quantitative and qualitative methods. In Experiment 1, participants (n=31) listened to robot sounds and described them using free-form text annotations. In Experiment 2, participants rated emotions conveyed by the sounds on a set of predefined emotional scales. For Experiment 1, analysis of text focused on aspects related to motion (activity) and emotion (valence), based on a categorization into the two-dimentional circumplex model of affect. For Experiment 2, ratings along emotional scales were analyzed using Two-Way Repeated Measures ANOVAs.
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Key Insights</h2>
                                            <p class="tm-text">Results suggested no strong coupling between the emotional expression of gestures and how sounds inherent to these movements were perceived by listeners; joyful gestures did not necessarily result in joyful sounds. In the second experiment, blended sonification was used to enhance and further clarify the emotional expression of the original robot sounds evaluated in the first experiment. Analysis of quantitative ratings revealed that the blended sonification successfully contributed to enhancement of the emotional message for sound models designed to convey frustration and joy. Our findings suggest that blended sonification guided by perceptual research on emotion in speech and music can successfully improve communication of emotions through robot sounds in auditory-only conditions.</p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                                    <div class="row">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Tools</h2>
                                                    <p class="tm-text">
                                                       R, Max/MSP, SPSS. 
                                                    </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Methods</h2>
                                                    <p class="tm-text">ANOVAs, text mining, sound synthesis, perceptual experiments, mixed methods, perceptual ratings.</p>     
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Links</h2>
                                                    <p class="tm-text">
                                                        <a class="link-opacity-10" href="https://link.springer.com/article/10.1007/s12369-021-00788-4">Publication</a>,
                                                        <a class="link-opacity-10" href="https://link.springer.com/article/10.1007/s12369-021-00788-4#availability-of-data-and-materials">files and data</a>, 
                                                        <a class="link-opacity-10" href="https://www.kth.se/hct/mid/research/smc/projects/sonao-1.895500">SONAO project</a>. 

                                                    </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>   
                                </div>                                 
                            
                        </div>                                        
                    </div>                    
                </li>

                <!-- Page 2  -->
                <li>
                    <div class="cd-full-width">
                        <div class="container-fluid js-tm-page-content" data-page-no="2" data-page-type="gallery">                        
                            <div class="tm-img-gallery-container">
                                <div class="tm-img-gallery gallery-two">
                                <!-- Gallery Two pop up connected with JS code below -->                                    
                                    <div class="tm-img-gallery-info-container">                                    
                                        <h2 class="tm-text-title tm-gallery-title"><span class="tm-white">The Gender Gap and the Computer Music Narrative</span></h2>
                                        <p class="tm-text"><span class="tm-white">On the Under-Representation of Women at Computer Music Conferences</span>
                                        </p>                                     
                                    </div>
                                    
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj2/fig3-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Three</span></h2>-->
                                                <p class="tm-figure-description">Workflow</p>
                                                <a href="img/projects/proj2/fig3.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                     <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj2/fig4-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Four</span></h2>-->
                                                <p class="tm-figure-description"> Female author names in the ICMC, SMC and NIME
                                                proceedings</p>
                                                <a href="img/projects/proj2/fig4.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj2/fig2-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Two</span></h2>-->
                                                <p class="tm-figure-description">Publication: ARRAY2021 – Diversity, pluralism – equity</p>
                                                <a href="img/projects/proj2/fig2.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                   
                                     <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj2/fig1-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>One</span></h2>-->
                                                <p class="tm-figure-description">Female vs unknown author names in the ICMC proceedings</p>
                                                <a href="img/projects/proj2/fig1.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                </div> <!-- .tm-img-gallery-container -->

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Background</h2>
                                                    <p class="tm-text">Although some of the first pioneers in computer science were women (see e.g. <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Ada_Lovelace">Ada Lovelace</a> and <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Grace_Hopper">Grace Hopper</a>), the field of computer music, as well as the <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Science,_technology,_engineering,_and_mathematics">STEM</a> fields in general, are still struggling with gender balance. As voiced by <a class="link-opacity-10" href="https://doi.org/10.1080/07494467.2016.1176764">Frida Abtan</a>: <i>“At conferences and workshops, there are always a few of us eyeing each other and asking ourselves: why are women still so under-represented in electronic music?”</i>  This question, which is still highly relevant, is the overarching premise of this work.
                                                    </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Aim</h2>
                                                    <p class="tm-text">The goal of this project was to estimate the number of female authors publishing articles in the proceedings of the most important conferences focused on Computer Music: <a class="link-opacity-10" href="https://smcnetwork.org/">Sound and Music Computing Conference (SMC)</a>, <a class="link-opacity-10" href="https://www.nime.org/">New Interfaces for Musical Expression (NIME)</a>, and <a class="link-opacity-10" href="https://www.computermusic.org/icmc-conference/">International Computer Music Conference (ICMC)</a>. 
                                                    </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>  
                                                  
                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                                    <h2 class="tm-text-title">Approach</h2>
                                                    <p class="tm-text">
                                                    Considerable time was dedicated to data collection and data cleaning; since there was no existing dataset readily available the source files had to be created from a range of external sources. Custom Python scripts were created for the purpose of constructing the dataset (primarily based on extracting info from PDF proceedings, lists published on conference webpages, or by parsing BibTex files). Gender prediction based on author names was subsequently carried out using the genderize.io API. This allowed for prediction with output into the following categories: <i>“male”</i>, <i>“female”</i> and <i>“none” (unknown)</i>. Manual search was subsequently performed for names labeled as unknown. The data was fitted to a model with Autoregressive Integrated Moving Average (ARIMA) errors. To further emphasize the size of the gap between number of female versus male author names in the dataset, the data was translated into sounds using <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Sonification">sonification</a>. </p> 
                                                </div>
                                            </div>
                                        </div>
                                    </div>

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                                    <h2 class="tm-text-title">Key Insights</h2>
                                                    <p class="tm-text">
                                                        The findings from this project are summarized in two publications, one published in 2017 and one in 2021. The first paper focuses on the gender gap in proceedings up til 2016, with findings suggested values consistently below 20% female author names. The second paper followed up on the previous work, including data until 2021. Findings highlighted that the gender gap was persistent and that the numbers had not drastically changed since 2016. However, temporal analysis of predicted genders of unique author names in the ICMC proceedings suggested a tendency towards higher percentages of female names in more recent years, with values ranging from 2.8% in 1981 to 16.2% in 2017, and an overall of 10.4% female names. The regression model indicted a positive increase in female author names of 0.17% (± 0.1) per year (p < .001). 

                                                    </p>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                    <div class="row">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Tools</h2>
                                                    <p class="tm-text">Python (numpy, pandas, <a class="link-opacity-10" href="https://genderize.io/">genderize</a>), LaTeX/BibTex, R (ggplot2, plotly), SuperCollider.</p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Methods</h2>
                                                    <p class="tm-text">ARIMA modeling, gender classification from text data, sound synthesis (granular synthesis).</p>     
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Links</h2>
                                                    <p class="tm-text"><a class="" href="">Publication (2021), <a class="https://www.researchgate.net/publication/320765100_Sonification_of_Women_in_Sound_and_Music_Computing_-_The_Sound_of_Female_Authorship_in_ICMC_SMC_and_NIME_Proceedings" href="https://journals.qucosa.de/array/article/download/3274/3092">publication (2017)</a>, <a class="link-opacity-10" href="https://youtu.be/rEgMKINIU5E">sound examples (2021)</a>, <a class="link-opacity-10" href="https://www.youtube.com/playlist?list=PLdmT_JtSFfHZgghEI3PtKMo-OeVyDodYk">sound examples (2017)</a>.</p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>   
                                </div>                                 
                            
                        </div>         
                    </div>  
                </li>

                <!-- Page 3 Gallery Three -->
                <li>
                    <div class="cd-full-width">
                        <div class="container-fluid js-tm-page-content" data-page-no="3" data-page-type="gallery">                        
                            <div class="tm-img-gallery-container">
                                <div class="tm-img-gallery gallery-three">
                                <!-- Gallery Two pop up connected with JS code below -->
                                    
                                    <div class="tm-img-gallery-info-container">                                    
                                        <h2 class="tm-text-title tm-gallery-title"><span class="tm-white">Music Creation by Example</span></h2>
                                        <p class="tm-text"><span class="tm-white">A user interface paradigm for video</span>
                                        </p>                                     
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj3/fig1-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>One</span></h2>-->
                                                <p class="tm-figure-description">GUI of the final prototype system</p>
                                                <a href="img/projects/proj3/fig1.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj3/fig2-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Two</span></h2>-->
                                                <p class="tm-figure-description">Project workflow</p>
                                                <a href="img/projects/proj3/fig2.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj3/fig3-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Three</span></h2>-->
                                                <p class="tm-figure-description">Features suggested by user test participants (U) vs expert evaluators (E)</p>
                                                <a href="img/projects/proj3/fig3.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj3/fig4-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Four</span></h2>-->
                                                <p class="tm-figure-description">Final design of UI grid</p>
                                                <a href="img/projects/proj3/fig4.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                </div> <!-- .tm-img-gallery-container -->
                                    
                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Background</h2>
                                                    <p class="tm-text">Short online videos have become the dominating media on social platforms. However, finding suitable music to accompany videos can be a challenging task to some video creators, due to copyright constraints, limitations in search engines, and required audio-editing expertise. One possible solution to these problems is to use AI music generation. In this work, we presented a user interface (UI) paradigm that allows users to input a song to an AI engine and then interactively regenerate and mix AI-generated music. This project was carried out in collaboration with the <a class="link-opacity-10" href="https://research.adobe.com/about-adobe-research/">Adobe - Creative Intelligence Lab</a> in San Francisco.</p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Aim</h2>
                                                    <p class="tm-text">
                                                        The aim of this work was to we explore new interface solutions that bridges AI solutions with non-expert users, balancing between automation and control, thereby making music generation more straightforward and easily accessible. 
                                                    </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>  
                                                  
                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                                    <h2 class="tm-text-title">Approach</h2>
                                                    <p class="tm-text">
                                                    To arrive at the final design of our system, we conducted a series of user studies using an iterative design process. First, we carried out several prestudies: 1) a formative study with video creators, 2) a brainstorming workshop with HCI researchers, 3) a user study with video creators demonstrating prototype solutions. Then, we evaluated the prototype system with potemtial users. Participants were asked to create music for a video based on example songs, using the system. This was followed by semi-structured interviews and evaluation questionnaires. Throughout the project, we conducted user studies with a total of 104 video creators at several stages of our design and development process. 
                                                    </p>
                                                </div>
                                            </div>
                                        </div>
                                    </div>

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                                    <h2 class="tm-text-title">Key Insights</h2>
                                                    <p class="tm-text">In this project we adopted a user centered approach to the design of a music generation system based on <i>“creation by example”</i>. Results from user studies suggested that there is a need for simpler and more easily accessible tools for generating music for video. We developed a system that allows for curation of AI music based on a UI paradigm allowing for interactive and iterative mixing of AI-generated material. Findings indicate that the designed system succeeded in meeting user needs; it was perceived as easy and enjoyable to use, require little learning time, and produce satisfying musical outcomes by the majority of the participants. The proposed UI paradigm can be useful to video creators since it enables music creation for video without requiring tedious search and editing processes. Finally, the user studies shed light on that it is important to balance the control assigned to the AI versus the human input; for creative tasks, there is a distinction between tasks that users want to leave to the AI, versus tasks that they want to perform themselves.</p>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                    <div class="row">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Tools</h2>
                                                    <p class="tm-text">Python, R (ggplot2), <a class="link-opacity-10" href="https://www.ibm.com/watson">IBM Watson</a> (Watson Beat, AI-powered music composition), <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Electron_(software_framework)">Electron</a>, <a class="link-opacity-10" href="https://www.usertesting.com/">User testing</a>, Max/MSP, VSTs for audio generation (MIDI), Adobe XD. </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Methods</h2>
                                                    <p class="tm-text">
                                                        User testing, online questionnaires, thematic content analysis, brainstorming workshops, parallel prototyping, semi-structured interviews, think-aloud, evaluation of Human-AI interaction, expert evaluation, wireframing.</p>     
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Links</h2>
                                                    <p class="tm-text">
                                                        <a class="link-opacity-10" href="https://dl.acm.org/doi/10.1145/3313831.3376514">Publication</a>, 
                                                        <a class="link-opacity-10" href="https://dl.acm.org/doi/10.1145/3313831.3376514#sec-supp">files and data</a>, 
                                                        <a class="link-opacity-10" href="https://youtu.be/2a8DzysMZTc?feature=shared">video example</a>.
                                                    </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>   
                                </div>                                 
                        </div>         
                    </div>  
                </li>

                <!-- Page 4  -->
                <li>
                    <div class="cd-full-width">
                        <div class="container-fluid js-tm-page-content" data-page-no="4" data-page-type="gallery">                        
                            <div class="tm-img-gallery-container">
                                <div class="tm-img-gallery gallery-four">
                                <!-- Gallery Two pop up connected with JS code below -->
                                    
                                    <div class="tm-img-gallery-info-container">                                    
                                        <h2 class="tm-text-title tm-gallery-title"><span class="tm-white">Customizing and Evaluating Accessible Multisensory Music Experiences with Pre-Verbal Children</span></h2>
                                        <p class="tm-text"><span class="tm-white">A Case Study on the Perception of Musical Haptics Using Participatory Design with Proxies</span>
                                        </p>                                     
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj5/fig1-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>One</span></h2>-->
                                                <p class="tm-figure-description">The Sound Forest installation - Scenkonstmuséet</p>
                                                <a href="img/projects/proj5/fig1.jpeg">View more</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj5/fig4-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Three</span></h2>-->
                                                <p class="tm-figure-description">Plots of the detected onsets and pitches triggered by user interaction</p>
                                                <a href="img/projects/proj5/fig4-tn.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                     <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj5/fig2-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Four</span></h2>-->
                                                <p class="tm-figure-description">Chewbacca - a Haptic Music Player developed for the study</p>
                                                <a href="img/projects/proj5/fig2.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj5/fig3-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Two</span></h2>-->
                                                <p class="tm-figure-description"> Body maps displaying perceptions of vibrations</p>
                                                <a href="img/projects/proj5/fig3.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                </div> <!-- .tm-img-gallery-container -->

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Background</h2>
                                                    <p class="tm-text">
                                                        Research on <i><a class="link-opacity-10" href="https://www.mdpi.com/2414-4088/3/3/57">Accessible Digital Musical Instruments</i></a> (accessible musical control interfaces used in electronic music, inclusive music practice, and music therapy settings, i.e. <i>ADMIs</i>) has highlighted the need for participatory design methods, that is, to actively include users as co-designers and informants in the design process. However, very little work has yet explored how pre-verbal children with Profound and Multiple Disabilities (PMLD) can be involved in such activities. In this project, we applied in-depth qualitative and mixed methodologies in a case study with four students with PMLD. PMLD is commonly used to describe a person with severe learning disabilities who most likely has other complex disabilities and health conditions. Using <i>Participatory Design with Proxies (PDwP)</i>, we assessed how these students could be involved in the customization and evaluation of the design of a multisensory music experience intended for a large-scale Accessible Digital Musical Instrument.
                                                    </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Aim</h2>
                                                    <p class="tm-text">The aim of this project was to create a customized multisensory experience informed by students’ needs, musical preferences, and abilities. An important aspect of this work was to explore tools and methods that could successfully enable a discussion about music and <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Haptic_perception">haptics</a> with the students. For example, how can we talk about concepts such as the perception of touch, using <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Augmentative_and_alternative_communication">Augmentative and Alternative Communication (AAC)</a>?</p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>  
                                                  
                                      <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Approach</h2>
                                            <p class="tm-text">
                                                This project was organised as a long-term collaboration with a student group, a teacher, and a group of teaching assistants at the school <a class="link-opacity-10" href="https://dibber.se/skola/rullens-sarskola/">Dibber Rullen</a> in Solna, Sweden, and the <a class="link-opacity-10" href="https://scenkonstmuseet.se/?lang=en">Museum of Performing Arts (Scenkonstmuséet)</a> in Stockholm, where our multisensory sound installation Sound Forest is hosted. The students that we collaborated with are mostly pre-verbal, meaning that they do not yet have verbal communication skills, and they all have multifunctional physical challenges, with varying motor skills, moderate to severe intellectual challenges. We used a range of different quantitative and qualitative methods to inform our design of the final multisensory experience to be displayed in Sound Forest. This included, for example, physical characterization of vibrating platforms in the sound installation, observational studies at the school, interviews with teachers, questionnaire studies with parents, and music listening sessions together with the students. The final design of the multisensory experience was evaluated through an experiment. The students were invited to explore the installation in four different conditions, sitting in wheel-chairs and lying on the floor, with haptic feedback turned on or off. Augmentative and Alternative Communication (AAC) tools were used to communicate with the students about their experiences. We also captured log and video data of all the events (e.g. interactions with sensors). Finally, we conducted a semi-structured group interview with the teacher and teaching assistants who attended the experiment together with the students, using a stimulated-recall methodology. 
                                            </p>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Key Insights</h2>
                                            <p class="tm-text"> Results suggested that the multisensory design worked well in terms of creating a relaxing and ever-changing sonic experience, with a constant yet not overwhelming vibration coming from the haptic floor. Our findings highlighted the diversity in interaction strategies used by the children, limitations in terms of the accessibility of the current multisensory experience design, and the importance of using a multifaceted variety of qualitative and quantitative methods to arrive at more informed conclusions when applying a <i>Participatory Design with Proxies</i> methodology. This work sheds light on methodological and design considerations that should be taken into account when developing multisensory experiences informed by pre-verbal children.</p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                                    <div class="row">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Tools</h2>
                                                    <p class="tm-text">Python, R, SuperCollider, Tombstone. </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Methods</h2>
                                                    <p class="tm-text">Acceleromenter measurements, Participatory Design with Proxies (PDwP), semi-structured interviews (stimulated recall), observational studies, questionnaires, body maps, micro phenomenological interviews, sound synthesis, evaluation methods.</p>     
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Links</h2>
                                                    <p class="tm-text">
                                                    <a class="link-opacity-10" href="https://www.mdpi.com/2414-4088/6/7/55">Publication (journal)</a>, <a class="link-opacity-10" href="https://doi.org/10.5281/zenodo.6464014"> data and files</a>,  
                                                    <a class="link-opacity-10" href="https://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-331144">publication (conference)</a>, <a class="link-opacity-10" href="https://www.kth.se/hct/mid/research/smc/projects/sound-forest-1.897050">Sound Forest project</a>.
                                                </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>   
                                </div>                                 
                            
                        </div>         
                    </div>  
                </li>

                <!-- Page 4  -->
                <li>
                    <div class="cd-full-width">
                        <div class="container-fluid js-tm-page-content" data-page-no="5" data-page-type="gallery">                        
                            <div class="tm-img-gallery-container">
                                <div class="tm-img-gallery gallery-five">
                                <!-- Gallery Two pop up connected with JS code below -->
                                    
                                    <div class="tm-img-gallery-info-container">                                    
                                        <h2 class="tm-text-title tm-gallery-title"><span class="tm-white">Sonification of Heart Signals</span></h2>
                                        <p class="tm-text"><span class="tm-white">Mapping Inter-cardiovascular Time-frequency Coherence to Harmonic Tension in Sonification of Ensemble Interaction Between a Covid-19 Patient and the Medical Team</span>
                                        </p>                                     
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj4/fig1-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>One</span></h2>-->
                                                <p class="tm-figure-description">Results for patient versus a medical team member</p>
                                                <a href="img/projects/proj4/fig1.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj4/fig2-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Two</span></h2>-->
                                                <p class="tm-figure-description">Distances in the pitch class helix of the spiral array</p>
                                                <a href="img/projects/proj4/fig2.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj4/fig3-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Three</span></h2>-->
                                                <p class="tm-figure-description">TFC (averaged over frequencies) between each patient and team member</p>
                                                <a href="img/projects/proj4/fig3.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                    <div class="grid-item">
                                        <figure class="effect-bubba">
                                            <img src="img/projects/proj4/fig4-tn.jpeg" alt="Image" class="img-fluid tm-img">
                                            <figcaption>
                                                <!--<h2 class="tm-figure-title">Figure <span>Four</span></h2>-->
                                                <p class="tm-figure-description"> Visualization of heartbeats and mean TFC</p>
                                                <a href="img/projects/proj4/fig4.jpeg">Enlarge</a>
                                            </figcaption>           
                                        </figure>
                                    </div>
                                     
                                </div> <!-- .tm-img-gallery-container -->

                                    <div class="row tm-white-box-margin-b">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Background</h2>
                                                    <p class="tm-text">During the COVID-19 pandemic, several attempts were made to make data more accessible using auditory representations (i.e., <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Sonification">sonifications</a> of data). The majority of these attempts focused on progression of the pandemic over time or aspects related to genomes and spike proteins. Little work in this context explored aspects related to the experiences of the patient and health workers directly impacted by COVID-19. In this project, we explored the potential of sonically representating heartbeats of a COVID-19 patient and a medical team using musical sonifications. A key focus of this work was to highlight how the medical team members came together when treating the patient, thus connecting to previous research on synchronization and <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Entrainment_(biomusicology)">entrainment</a>. 

                                                    </p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Aim</h2>
                                                    <p class="tm-text">
                                                    The aim of this work was to sonify heart signals to reflect how a medical team comes together during a COVID-19 treatment. More specifically, the goal was to explore Time-Frequency Coherence (TFC) and heartbeat rhythms within this group, using sonic representations.  </p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>  
                                                  
                             <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Approach</h2>
                                            <p class="tm-text">
                                                We used <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Heart_rate_variability">Heart Rate Variability</a> (HRV, a beat to beat variance measures), and Time Frequency Coherence (TFC, an estimation of spectral coherence, i.e. the degree of correlation between the spectral components of two signals in the joint time-frequency domain), to assess degree of similarity between two heart signals over different frequencies. TFC was be used to evaluate HRV coupling between two individuals’ heart signals, which was also sonified and visualized. A rule-based system was implemented to map this relationship to sounds, based on consonance and dissonance in music. More specifically, the average TFC between the patient and respective medical team member was mapped to distance between pitches in the <a class="link-opacity-10" href="https://en.wikipedia.org/wiki/Spiral_array_model">spiral array</a>. As such, the system enabled creation of sounds representing the relationship between the heartsignals of the patient versus the medical team members. The sound generation system was evaluted through a web-based listening experiment with n=41 participants, with stimuli presented in two conditions: coherent versus incoherent signals (corresponding to consonant versus dissonant sounds). 
                                            </p>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <div class="row tm-white-box-margin-b">
                                <div class="col-xs-12">
                                    <div class="tm-flex">
                                        <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-textbox-padding">
                                            <h2 class="tm-text-title">Key Insights</h2>
                                            <p class="tm-text">Results from the listening experiment suggested that the proposed mapping between TFC and consonance versus dissonance was successful in communicating low versus high coherence between heart signals, with an overall accuracy of 69% (significantly higher than chance). Our work highlights synergies between sound and heart signals through mapping between TFC of heart signals and harmonic tension and dissonance in music.Findings suggest that links between heart-and sound signals could be further explored through sonification to promote understanding of aspects related to cardiovascular health. </p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                                    <div class="row">
                                        <div class="col-xs-12">
                                            <div class="tm-flex">
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Tools</h2>
                                                    <p class="tm-text">MATLAB, Python, R, SuperCollider, Processing, OSC.</p>
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Methods</h2>
                                                    <p class="tm-text">Poisson regression analysis, chi-squared tests, visualization, evaluation experiments, sound synthesis.</p>     
                                                </div>
                                                <div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox-2 tm-textbox-padding">
                                                    <h2 class="tm-text-title">Links</h2>
                                                    <p class="tm-text">
                                                        <a class="link-opacity-10", href="https://hal.science/hal-03277425">Publication</a>,
                                                        <a class="link-opacity-10" href="https://drive.google.com/drive/folders/17z2m3xwkK-ySipwrU6UHoxXR5BxU9hmp"> files and data (including sound examples)</a>, 
                                                        <a class="link-opacity-10" href="https://cosmos.isd.kcl.ac.uk/">COSMOS and Heart.FM project</a>.</p>     
                                                </div>
                                            </div>
                                        </div>
                                    </div>   
                                </div>                                 
                            
                        </div>         
                        
                    </div> <!-- .cd-full-width -->
                </li>
            </ul> <!-- .cd-hero-slider -->
            
            <footer class="tm-footer">
            
                <div class="tm-social-icons-container text-xs-center">
                    <a href="https://github.com/emmenru" class="tm-social-link"><i class="fa fa-github"></i></a>
                    <a href="https://scholar.google.com/citations?user=0PvSz8cAAAAJ&hl=eng" class="tm-social-link"><i class="fa fa-google"></i></a>
                    <a href="https://emserpics.tumblr.com/" class="tm-social-link"><i class="fa fa-twitter"></i></a>
                    <!--<a href="#" class="tm-social-link"><i class="fa fa-behance"></i></a>-->
                    <a href="https://www.linkedin.com/in/emmafrid" class="tm-social-link"><i class="fa fa-linkedin"></i></a>
                </div>
                
                <!--
                <p class="tm-copyright-text">Copyright &copy; 2017 Your Company 
                
                 - Design: Tooplate</p>
                -->

            </footer>
                    
        </div> <!-- .cd-hero -->
        

        <!-- Preloader, https://ihatetomatoes.net/create-custom-preloading-screen/ -->
        <div id="loader-wrapper">
            
            <div id="loader"></div>
            <div class="loader-section section-left"></div>
            <div class="loader-section section-right"></div>

        </div>
        
        <!-- load JS files -->
        <script src="js/jquery-1.11.3.min.js"></script>         <!-- jQuery (https://jquery.com/download/) -->
        <script src="https://www.atlasestateagents.co.uk/javascript/tether.min.js"></script> <!-- Tether for Bootstrap (http://stackoverflow.com/questions/34567939/how-to-fix-the-error-error-bootstrap-tooltips-require-tether-http-github-h) --> 
        <script src="js/bootstrap.min.js"></script>             <!-- Bootstrap js (v4-alpha.getbootstrap.com/) -->
        <script src="js/hero-slider-main.js"></script>          <!-- Hero slider (https://codyhouse.co/gem/hero-slider/) -->
        <script src="js/jquery.magnific-popup.min.js"></script> <!-- Magnific popup (http://dimsemenov.com/plugins/magnific-popup/) -->
        
        <script>

            function adjustHeightOfPage(pageNo) {

                var offset = 80;
                var pageContentHeight = 0;

                var pageType = $('div[data-page-no="' + pageNo + '"]').data("page-type");

                if( pageType != undefined && pageType == "gallery") {
                    pageContentHeight = $(".cd-hero-slider li:nth-of-type(" + pageNo + ") .tm-img-gallery-container").height();
                }
                else {
                    pageContentHeight = $(".cd-hero-slider li:nth-of-type(" + pageNo + ") .js-tm-page-content").height() + 20;
                }

                if($(window).width() >= 992) { offset = 120; }
                else if($(window).width() < 480) { offset = 40; }
               
                // Get the page height
                var totalPageHeight = $('.cd-slider-nav').height()
                                        + pageContentHeight + offset
                                        + $('.tm-footer').height();

                // Adjust layout based on page height and window height
                if(totalPageHeight > $(window).height()) 
                {
                    $('.cd-hero-slider').addClass('small-screen');
                    $('.cd-hero-slider li:nth-of-type(' + pageNo + ')').css("min-height", totalPageHeight + "px");
                }
                else 
                {
                    $('.cd-hero-slider').removeClass('small-screen');
                    $('.cd-hero-slider li:nth-of-type(' + pageNo + ')').css("min-height", "100%");
                }
            }

            /*
                Everything is loaded including images.
            */
            $(window).load(function(){

                adjustHeightOfPage(1); // Adjust page height

                /* Gallery One pop up
                -----------------------------------------*/
                $('.gallery-one').magnificPopup({
                    delegate: 'a', // child items selector, by clicking on it popup will open
                    type: 'image',
                    gallery:{enabled:true}                
                });
                
                /* Gallery Two pop up
                -----------------------------------------*/
                $('.gallery-two').magnificPopup({
                    delegate: 'a',
                    type: 'image',
                    gallery:{enabled:true}                
                });

                /* Gallery Three pop up
                -----------------------------------------*/
                $('.gallery-three').magnificPopup({
                    delegate: 'a',
                    type: 'image',
                    gallery:{enabled:true}                
                });

                /* Gallery Four pop up
                -----------------------------------------*/
                $('.gallery-four').magnificPopup({
                    delegate: 'a',
                    type: 'image',
                    gallery:{enabled:true}                
                });

                 /* Gallery Five pop up
                -----------------------------------------*/
                $('.gallery-five').magnificPopup({
                    delegate: 'a',
                    type: 'image',
                    gallery:{enabled:true}                
                });

                /* Collapse menu after click 
                -----------------------------------------*/
                $('#tmNavbar a').click(function(){
                    $('#tmNavbar').collapse('hide');

                    adjustHeightOfPage($(this).data("no")); // Adjust page height       
                });

                /* Browser resized 
                -----------------------------------------*/
                $( window ).resize(function() {
                    var currentPageNo = $(".cd-hero-slider li.selected .js-tm-page-content").data("page-no");
                    
                    // wait 3 seconds
                    setTimeout(function() {
                        adjustHeightOfPage( currentPageNo );
                    }, 1000);
                    
                });
        
                // Remove preloader (https://ihatetomatoes.net/create-custom-preloading-screen/)
                $('body').addClass('loaded');
                           
            });

            /* Google map
            ------------------------------------------------*/
            var map = '';
            var center;

            function initialize() {
                var mapOptions = {
                    zoom: 14,
                    center: new google.maps.LatLng(37.769725, -122.462154),
                    scrollwheel: false
                };
            
                map = new google.maps.Map(document.getElementById('google-map'),  mapOptions);

                google.maps.event.addDomListener(map, 'idle', function() {
                  calculateCenter();
                });
            
                google.maps.event.addDomListener(window, 'resize', function() {
                  map.setCenter(center);
                });
            }

            function calculateCenter() {
                center = map.getCenter();
            }

            function loadGoogleMap(){
                var script = document.createElement('script');
                script.type = 'text/javascript';
                script.src = 'https://maps.googleapis.com/maps/api/js?v=3.exp&sensor=false&' + 'callback=initialize';
                document.body.appendChild(script);
            }
        
            // DOM is ready
            $(function() {                
                loadGoogleMap(); // Google Map
            });

        </script>            

</body>
</html>